{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2cc996",
   "metadata": {},
   "source": [
    "# gdir_preprocessing.ipynb\n",
    "\n",
    "Brandon S. Tober<br>\n",
    "\n",
    "23JUL2025<br>\n",
    "\n",
    "This notebook demonstrates how OGGM glacier directories can be compressed after some preprocessing.  Say we perform bed inversion and then dynamical spinup, and wish to store a set of compressed glacier directories afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff4798",
   "metadata": {},
   "source": [
    "First, run OGGMs ice thickness/bed inversion using PyGEM's mass balance model\n",
    "\n",
    "```bash\n",
    "run_inversion -rgi_region01 1 -ncores 6\n",
    "```\n",
    "\n",
    "Second, perform dyncamical spinup, using PyGEM's mass balance model\n",
    "\n",
    "```bash\n",
    "run_spinup -rgi_region01 1 -target_yr 2000 -ncores 6 \n",
    "```\n",
    " \n",
    "Both the above example steps will run for all glaciers in RGI region 1. for spinup, we could instead pass a list of glaciers to run (`-rgi_glac_number_fn` argument), or specify particular glaciers (`-rgi_glac_number` argument).\n",
    "\n",
    "After we perform these steps, we may wish to compress out preprocessed glacier directories.\n",
    "\n",
    "OGGM's `utils.gdir_to_tar()` method will compress individual gdirs (given a list of gdirs). Then, OGGM's `utils.base_dir_to_tar()` method will bundle individual gdir tars to a base-level directory tar.\n",
    "\n",
    "```python\n",
    "\n",
    "import oggm.cfg as cfg\n",
    "from oggm import utils, workflow, tasks\n",
    "import pygem.setup.config as config\n",
    "import geopandas as gpd\n",
    "\n",
    "# read pygem config\n",
    "pygem_prms = config.read_config()\n",
    "# Initialize OGGM and set up the default run parameters\n",
    "cfg.initialize(logging_level='WARNING')\n",
    "# set working directory\n",
    "cfg.PATHS['working_dir'] =f\"{pygem_prms['root']}/{pygem_prms['oggm']['oggm_gdir_relpath']}\"\n",
    "cfg.PARAMS['border'] = 80\n",
    "rgi_ids = gpd.read_file(utils.get_rgi_region_file('01', version='62'))['RGIId'].tolist()\n",
    "# probably want to use multiprocessing\n",
    "cfg.PARAMS['use_multiprocessing']=True\n",
    "# initialize gdirs from working_dir\n",
    "gdirs = workflow.init_glacier_directories(rgi_ids);\n",
    "# tar the individual glacier directories first\n",
    "workflow.execute_entity_task(utils.gdir_to_tar, gdirs, delete=True);\n",
    "# then tar the bundles\n",
    "utils.base_dir_to_tar(cfg.PATHS['working_dir'], delete=True);\n",
    "\n",
    "# now, say we wish to reload a set of glacier directories:\n",
    "gdirs = workflow.init_glacier_directories(rgi_ids, from_tar=True);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7714201",
   "metadata": {},
   "source": [
    "Say we want to run L4p preprocessing (level 4 \"PyGEM\") on all RGI regions:\n",
    "\n",
    "```bash\n",
    "# define regions of interest\n",
    "regions=($(seq 1 19))\n",
    "# how many cores to use\n",
    "ncores=128\n",
    "# run inversion script\n",
    "run_inversion -rgi_region01 \"${regions[@]}\" -ncores $ncores\n",
    "# run spinup script\n",
    "run_spinup -rgi_region01 \"${regions[@]}\" -ncores $ncores\n",
    "# compress gdirs\n",
    "compress_gdirs -rgi_region01 \"${regions[@]}\" -ncores $ncores\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "pygem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
