{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The Python Glacier Evolution Model (PyGEM) is an open-source glacier evolution model coded in Python that is designed to model the transient evolution of glaciers on regional and global scales. Each glacier is modeled independently using a given time step and elevation bins. The model computes the climatic mass balance (i.e., snow accumulation minus melt plus refreezing) for each elevation bin and each monthly time step. Glacier geometry is updated annually. The model outputs a variety of data including monthly mass balance and its components (accumulation, melt, refreezing, frontal ablation, glacier runoff),  and annual volume, volume below sea level, and area.\n",
    "\n",
    "PyGEM has a modular framework that allows different schemes to be used for model calibration or model physics (e.g., ablation, accumulation, refreezing, glacier dynamics). The most recent version of PyGEM, published in <em>Science</em> [(Rounce et al. 2023)](https://www.science.org/doi/10.1126/science.abo1324), has been made compatible with the Open Global Glacier Model [(OGGM)](https://oggm.org/) to both leverage the pre-processing tools (e.g., digital elevation models, glacier characteristics) and their advances with respect to modeling glacier dynamics and ice thickness inversions.\n",
    "\n",
    "```{note}\n",
    "Looking for a quick overview? Check out the [Model Structure and Workflow](model_structure_and_workflow_target).\n",
    "<br>Want to read some studies?  Check out our [publications](publications_target)!\n",
    "<br>Want to see what PyGEM can do? Check out this [presentation about PyGEM's latest developments](https://www.youtube.com/watch?v=gaGzEIjIJlc)!\n",
    "```\n",
    "\n",
    "## Citing PyGEM\n",
    "The most recent version of PyGEM was published in <em>[Science](https://www.science.org/doi/10.1126/science.abo1324)</em>. Therefore, if using PyGEM, please cite:\n",
    "<br><br>Rounce, D.R., Hock, R., Maussion, F., Hugonnet, R., Kochtitzky, W., Huss, M., Berthier, E., Brinkerhoff, D., Compagno, L., Copland, L., Farinotti, D., Menounos, B., and McNabb, R.W. (2023). “Global glacier change in the 21st century: Every increase in temperature matters”, <em>Science</em>, 379(6627), pp. 78-83, doi:10.1126/science.abo1324.\n",
    "\n",
    "```{figure} _static/science_cover.jpg\n",
    "---\n",
    "width: 50%\n",
    "---\n",
    "```\n",
    "\n",
    "## Contact us\n",
    "The PyGEM community is growing! As the community grows, we hope individuals will continue to support one another. For now, if you have questions, we recommend emailing David Rounce (drounce@cmu.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(model_structure_and_workflow_target)=\n",
    "# Model Structure and Workflow\n",
    "The model is written in Python. The model is currently available as two repositories on github:\n",
    "\n",
    "1. **PyGEM** ([https://github.com/drounce/PyGEM](https://github.com/drounce/PyGEM)) contains the main model code.  This repository can be installed in your environment with PyPI ([https://pypi.org/project/pygem/](https://pypi.org/project/pygem/)) using \"pip install pygem\".\n",
    "\n",
    "2. **PyGEM-scripts** ([https://github.com/drounce/PyGEM-scripts](https://github.com/drounce/PyGEM-scripts)) contains general scripts used to run the model (e.g., run_calibration.py, run_simulation.py) as well as the post-processing, analysis scripts (e.g., analyze_simulations.py). To use these files and run the model one must clone or fork the github repository onto your local machine.\n",
    "\n",
    "All input parameters are specified in the pygem_input.py file, which needs to be adjusted according to the specific datasets and model options of each user. The input file is [well documented](pygem_input_overview_target) and [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ) are produced to support trial runs. See the [Install_PyGEM](install_pygem_target) section for more details on installing the model.\n",
    "\n",
    "## Spatial and Temporal Resolution\n",
    "PyGEM models each glacier independently using a monthly timestep and elevation bins. We plan to add options to include daily timesteps in the near future and plan to develop new calibration options that can leverage regional datasets as well.\n",
    "\n",
    "(directory_structure_target)=\n",
    "## Directory structure\n",
    "Currently, the model does not have a “required” set of directories. For simplicity with github, we highly recommend keeping the forked version of the code in its own directory. Furthermore, since many of the datasets that will be used for regional and global model runs are of considerable size, we encourage users to develop their own organized file structure. The code has been developed to automatically set up all file paths using relative paths from the PyGEM-Scripts directory, which is where the code is run from the command line. The easiest way to run PyGEM will be to use the same directory structure as the developers (see [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ)):\n",
    "\n",
    "* [climate_data](climate_data_target)\n",
    "  - This directory contains the reference and future climate data\n",
    "* [debris_data](input_debris_data_target) (optional)\n",
    "  - This directory contains data concerning the debris thickness and sub-debris melt enhancement factors. \n",
    "* [DEMs](input_mb_data_target)\n",
    "  - This directory contains the geodetic mass balance data derived from DEM differencing that is used for calibration.\n",
    "* [IceThickness_Farinotti](input_thickness_data_target) (optional)\n",
    "  - This directory includes the consensus ice thickness estimates (Farinotti et al. 2019). The directory is optional unless you want to match the consensus ice thickness estimates.\n",
    "* [oggm_gdirs](input_glacier_data_target)\n",
    "  - This directory contains the glacier directories downloaded from OGGM. This directory will be automatically generated by the pre-processing steps from OGGM.\n",
    "* Output\n",
    "  - This directory contains all model output\n",
    "* PyGEM (optional)\n",
    "  - This directory contains all model functions and is used when in development mode if pygem is not installed in the conda environment.\n",
    "* [PyGEM-scripts](scripts_overview_target)\n",
    "  - This directory contains scripts to run the model and process output\n",
    "* [RGI](input_glacier_inventory_target)\n",
    "  - This directory contains the RGI glacier information\n",
    "* [WGMS](input_mb_data_target) (optional)\n",
    "  - This directory contains the WGMS mass balance data for validation. The directory is optional in case you prefer to validate your model with different data.\n",
    "  \n",
    "```{warning}\n",
    "If you use a different file structure and do not update the file paths in the **pygem_input.py**, you will get an error and PyGEM will not run!\n",
    "```\n",
    "\n",
    "(model_workflow_target)=\n",
    "## Model Workflow\n",
    "The model code itself is heavily commented with the hope that the code is easy to follow and develop further. After [installing PyGEM](install_pygem_target), downloading the required [input files](model_inputs_target), and setting up the [directory structure](directory_structure_target) (or modifying the **pygem_input.py** with your preferred directory structure) you are ready to run the code! Generally speaking, the workflow includes:\n",
    "* [Pre-process data](preprocessing_target) <em>(optional if including more data)</em>\n",
    "* [Set up input file](input_workflow_target)\n",
    "* [Calibrate frontal ablation parameter](workflow_cal_frontalablation_target) <em>(optional for marine-terimating glaciers)</em>\n",
    "* [Calibrate mass balance parameters](workflow_cal_prms_target)\n",
    "* [Calibrate ice viscosity parameter](workflow_cal_glena_target)\n",
    "* [Run model simulation](workflow_sim_target)\n",
    "* [Post-process output](workflow_post_target)\n",
    "* [Analyze output](workflow_analyze_target)\n",
    "\n",
    "\n",
    "(preprocessing_target)=\n",
    "### Pre-processing \n",
    "We rely heavily on [OGGM's pre-processing modules](https://docs.oggm.org/en/stable/shop.html), which are state-of-the-art. For most people, these glacier directories will be sufficient to get started. However, there are times when we work with different datasets and need to do our own pre-processing. For example, the following script corrects the geodetic mass balance from [Hugonnet et al. (2021)](https://www.nature.com/articles/s41586-021-03436-z) to account for the mass lost below the water level due to frontal ablation from [Kochtitzky et al. (2022)](https://www.nature.com/articles/s41467-022-33231-x).\n",
    "```\n",
    "python run_preprocessing_wgms_mbdata.py -mb_data_removeFA=1\n",
    "```\n",
    "\n",
    "\n",
    "(input_workflow_target)=\n",
    "### Set up input file\n",
    "**pygem_input.py** is the input file where the user can specify the glaciers/regions to model; model physics, calibration, and simulation options; relative filepaths for relevant datasets; etc. \n",
    "\n",
    "For more details, see the [pygem_input.py Script Overview](pygem_input_overview_target).\n",
    "\n",
    "```{note}\n",
    "The first time you process glacier directories (e.g., happens automatically with the run_calibration.py), you want to set <em>overwrite_gdirs=True</em> in pygem_input.py. This will add the mass balance and consensus ice thickness data to the glacier directories.  To avoid redownloading/reprocessing the glacier directories every time, after performed once set <em>overwrite_gdirs=False</em>.\n",
    "```\n",
    "\n",
    "(workflow_cal_prms_target)=\n",
    "### Calibrate mass balance model parameters\n",
    "The model parameters (degree-day factor of snow, precipitation factor, and temperature bias) must be calibrated for model results to be meaningful. This is done using **run_calibration.py**. Several options exist (see [Model Calibration](calibration_target) for specific details), but generally speaking the <em>option_calibration</em> will be specified in **pygem_input.py** and then the following is run:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "```{note}\n",
    "The Markov Chain Monte Carlo (MCMC) methods require several steps and additional python packages (i.e., PyMC2 and its dependencies. See [MCMC methods](MCMC_target) or [Test MCMC methods](test_advanced_target) for the specific workflow.\n",
    "```\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../Output/calibration/\\[RGI Order 1 region\\]/\\[glac_no\\]-model_prms.pkl \n",
    "* additional files will be generated if using the emulator\n",
    "\n",
    "For more details, see the [run_calibration.py Script Overview](run_calibration_target).\n",
    "\n",
    "\n",
    "(workflow_cal_frontalablation_target)=\n",
    "### Calibrate frontal ablation parameter\n",
    "**(Optional)** If you want to account for frontal ablation associated with marine-terminating glaciers, then the frontal ablation parameter needs to be calibrated. This is done using **run_calibration_frontalablation.py** with the following steps:\n",
    "\n",
    "First, merge the frontal ablation data together into a single directory:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_data = True)\n",
    "```\n",
    "Calibrate the frontal ablation parameter for each marine-terminating glacier:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_ind_calving_k = True)\n",
    "```\n",
    "Merge all the frontal ablation parameters into a single file:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_calving_k = True)\n",
    "```\n",
    "Update the climatic-basal mass balance data by removing the frontal ablation from the total mass change:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_update_mb_data = True)\n",
    "```\n",
    "```{note}\n",
    "The run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. \n",
    "```\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../calving_data/analysis/all-calving_cal_ind.csv\n",
    "* ../DEMs/Hugonnet2020/df_pergla_20yr-filled-FAcorrected.csv\n",
    "\n",
    "For more details, see the [run_calibration_frontalablation.py Script Overview](run_calibration_fa_overview_target).\n",
    "\n",
    "```{warning}\n",
    "Circularity issues exist in calibrating the frontal ablation parameter as the mass balance model parameters are required to estimate the ice thickness, but the frontal ablation will affect the mass balance estimates and thus the mass balance model parameters. We suggest taking an iterative approach: calibrate the mass balance model parameters, calibrate the frontal ablation parameter, update the glacier-wide climatic mass balance, and recalibrate the mass balance model parameters.\n",
    "```\n",
    "\n",
    "\n",
    "(workflow_cal_glena_target)=\n",
    "### Calibrate ice viscosity model parameter\n",
    "The ice viscosity (\"Glen A\") model parameter is calibrated such that the ice volume estimated using the calibrated mass balance gradients are consistent with the consensus ice volume estimates ([Farinotti et al. 2019]((https://www.nature.com/articles/s41561-019-0300-3))) for each RGI region. This is done by running the following:\n",
    "```\n",
    "python run_calibration_icethickness_consensus.py\n",
    "```\n",
    "```{note}\n",
    "This code is hard-coded and thus the user will have to go in and change regions.\n",
    "```\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../Output/calibration/‘glena_region.csv’ \n",
    "\n",
    "For more details, see the [run_calibration_icethickness.py Script Overview](run_calibration_icethickness_overview_target).\n",
    "\n",
    "\n",
    "(workflow_sim_target)=\n",
    "### Run model simulation\n",
    "Model simulations are performed using run_simulation.py. If no GCMs are specified in the command line, the default will be to run a model simulation with the reference data (e.g., ERA5). We currently recommend that <br><em>**historical simulations**</em> be performed without evolving the glacier geometry; thus, <em>option_dynamics = None</em> in **pygem_input.py** and the <em>ref_startyear</em> and <em>ref_endyear</em> are used to set the length of the simulation. The simulation can then be run using the following:\n",
    "```\n",
    "python run_simulation.py\n",
    "```\n",
    "<em>**Future simulations**</em> require specifying a GCM and scenario, which is passed to the script through the argument parser. For example, the following will run a simulation for CESM2 SSP2-4.5:\n",
    "```\n",
    "python run_simulation.py -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "```{note}\n",
    "For future simulations, at a minimum the user should specify the dynamical option (<em>option_dynamics</em>), start year (<em>gcm_startyear</em>), end year (<em>gcm_endyear</em>), bias correction option (<em>option_bias_adjustment</em>).\n",
    "```\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../Output/simulation/\\[RGI Order 1 region\\]/\\[GCM name\\]/\\[Scenario\\]/stats/\\[glac_no\\]_\\[GCM name\\]_\\[Scenario\\]_\\[Calibration Option\\]_ba\\[bias adjustment option\\]_\\[number of simulations\\]_\\[start year\\]_\\[end year\\]_all.nc\n",
    "* additional netcdf files may be output based on the user specifications in pygem_input.py\n",
    "\n",
    "For more details, see the [run_simulation.py Script Overview](run_simulation_target).\n",
    "\n",
    "\n",
    "(workflow_post_target)=\n",
    "### Post-process output\n",
    "There are currently several scripts available to process the datasets (e.g., merge them into regional files, create multi-GCM means and standard deviations for each SSP). While these scripts are well documented in line, they still need to be cleaned up for more widespread use.  An example:\n",
    "```\n",
    "python process_simulation.py\n",
    "```\n",
    "\n",
    "\n",
    "(workflow_analyze_target)=\n",
    "### Analyze output\n",
    "All users will analyze PyGEM output in different ways. The following is thus not meant to be an exhaustive list of analyses, but rather to provide some general scripts to produce diagnostic figures of mass, area, runoff, and ice thickness change. These scripts will also help you get familiar with working with the model and post-processed outputs. We are currently provide these scripts as Jupyter Notebooks, so you can visualize the expected output and use this to guide your efforts. These will be listed in <em>PyGEM-scripts</em> beginning with \"analyze_\". For example:\n",
    "* **analyze_glacier_change_byRGIRegion.ipynb**\n",
    "  - This notebook shows mass, area, and runoff changes with model output aggregated to RGI regions. Note that this notebook relies on [post-processed output](workflow_post_target).\n",
    "* **analyze_glacier_change_byWatershed.ipynb**\n",
    "  - This notebook shows mass, area, and runoff changes with model output aggregated to user-specified groups (watersheds are used in this example). Note that this notebook relies on [post-processed output](workflow_post_target). \n",
    "<br>For individual glacier changes, we recommend:\n",
    "* **analyze_glacier_change_CrossSection.ipynb**\n",
    "  - This notebook shows a cross section of ice thickness change and normalized mass change for a single glacier.\n",
    "\n",
    "At present, publication-quality figures of mass, area, and runoff change are also provided in case you want to investigate more complex figures. Figure options and pathways are hard-coded within these scripts. An example:\n",
    "```\n",
    "python analysis_Science_figs.py\n",
    "```\n",
    "\n",
    "For more detail, see [Model Output Section](model_output_overview_target)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(model_inputs_target)=\n",
    "# Model Inputs\n",
    "The minimum data required to run the model is a glacier inventory, glacier characteristics (ice thickness, hypsometry, etc.), climate data, and mass balance data for calibration ([Table 1](model_input_table_target)). The model uses glacier outlines provided by the [Randolph Glacier Inventory](https://www.glims.org/RGI/) (RGI Consortium 2017; RGI 6.0 contains 215,547 glaciers globally). For debris-covered glaciers, spatially distributed sub-debris melt enhancement factors can be used to account for the enhanced or suppressed melting depending on the debris thickness [(Rounce et al. 2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311). OGGM is used to select a digital elevation model (DEM) for each glacier and bin the data according to the glacier central flowlines. OGGM can also be used to estimate each glacier’s initial ice thickness or use existing ice thickness estimates available from the [OGGM Shop](https://docs.oggm.org/en/stable/shop.html).\n",
    "\n",
    "For present-day (2000-2019) model runs, PyGEM currently uses monthly near-surface air temperature and precipitation data from ERA5 [(Hersbach et al. 2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3803). Air temperature lapse rates are estimated using monthly air temperature data from various pressure levels. A second option is available to derive lapse rates from the neighboring pixels; however, this is for glaciers near the coast and therefore is not recommended. Additionally, the monthly temperature standard deviation is required if incorporating sub-monthly temperature variability in ablation (see below). Note that historical runs (e.g., 1980-2000) are challenging due to the lack of glacier inventories in the past; hence, one can assume the glacier area is constant or run the model in reverse (e.g., 1999, 1998, ... , 1980). However, due to nonlinearities associated with the glacier dynamics running if the model is run in reverse and then forward, the glacier areas will be different in 2000 than the initial dataset; hence, caution must be used and the results should be evaluated carefully.\n",
    "\n",
    "For future (e.g., 2000-2100) model runs, PyGEM currently uses an ensemble of General Circulation Models (GCMs) and Shared Socioeconomic Pathways (SSPs) from the Coupled Model Intercomparison Project Phase 6 (CMIP6). The model can also be run using Representative Concentration Pathways (RCPs) associated with CMIP5. Future simulations are adjusted using additive factors for air temperature and multiplicative factors for precipitation to remove any bias between the GCMs and ERA5 data over the calibration period (2000-2019). Additional bias corrections options will be available in the future.\n",
    "\n",
    "(model_input_table_target)=\n",
    "**Table 1.** Data requirements for PyGEM. Optional datasets are shown in italics.\n",
    "\n",
    "| Component | Dataset | References |\n",
    "| :--- | :--- | :--- |\n",
    "| [Glacier data](input_glacier_inventory_target) | Randolph Glacier Inventory Version 6.0 | [RGI Consortium (2017)](https://www.glims.org/RGI/) |\n",
    "| [Climate data](climate_data_target) | 1: ERA5 monthly air temperature, monthly precipitation, and orography <br><em>2: ERA5 monthly lapse rates (from pressure level data) and monthly air temperature variance (from ERA5 hourly data)</em> <br>3: CMIP5 or CMIP6 monthly air temperature, monthly precipitation, and orography | [Hersbach et al. (2020)](https://rmets.onlinelibrary.wiley.com/doi/full/10.1002/qj.3803) |\n",
    "| [Mass balance data](input_mb_data_target) | 1: Geodetic glacier-wide mass balance (m w.e. yr$^{-1}$) <br>2: Glaciological glacier-wide mass balance (m w.e. yr$^{-1}$) <br><em>3: All other data need to be programmed</em> | [Hugonnet et al. (2021)](https://www.nature.com/articles/s41586-021-03436-z) <br> [WGMS (2021)](https://wgms.ch/data_databaseversions/) |\n",
    "| [Debris data](input_debris_data_target) (optional) | <em>Sub-debris melt factors </em> | [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) |\n",
    "| [Frontal ablation data](input_fa_data_target) (optional) | <em>1: Frontal ablation per glacier (Gt yr-1) <br>Used to calibrate marine-terminating glaciers </em> | [Osmanoglu et al. (2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014)](https://tc.copernicus.org/articles/8/1807/2014/); [Minowa et al. (2021)](https://www.sciencedirect.com/science/article/pii/S0012821X21000704); [Kochtitzky et al. (2022)](https://www.nature.com/articles/s41467-022-33231-x) |\n",
    "| [Ice thickness data](input_thickness_data_target) (optional) </em>| <em>Spatially distributed ice thickness data <br>Used to calibrate creep parameter to match volume of existing ice thickness dataset </em>| [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3)|\n",
    "\n",
    "```{note}\n",
    "A sample of all relevant data to perform a test run of the model is provided [here](https://drive.google.com/file/d/159zS-oGWLHG9nzkFdsf6Uh4-w9lJSt8H/view?usp=sharing). The different sources of data required to run the model are provided below including instructions on where to download the data. We recommend reviewing the sample data to address any questions you may have concerning the structure of the datasets.\n",
    "```\n",
    "\n",
    "(input_glacier_inventory_target)=\n",
    "## Glacier Inventory\n",
    "The current model structure of defining the glaciers uses the Randolph Glacier Inventory version 6.0 (RGI Consortium 2017), but theoretically any glacier inventory that uses the same format and provides the same information (e.g., RGIId, Area, Terminus Type, Median elevation) would be applicable. The glacier inventory is formatted as a .csv file. The latest version of the RGI can be downloaded [here](https://www.glims.org/RGI/).\n",
    "\n",
    "(input_glacier_data_target)=\n",
    "## Glacier Data\n",
    "The mass balance model can be run with information concerning glacier hypsometry; however, to account for glacier dynamics, the model requires information concerning the glacier's ice thickness as well. These data are available through the Glacier Model Intercomparison Project (GlacierMIP) (Marzeion et al. 2020) or can be derived workflows from OGGM ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)). We recommend using pre-processed glacier direcotry from the [OGGM Shop](https://docs.oggm.org/en/stable/shop.html).\n",
    "\n",
    "There are several options for pre-processed data from OGGM and we recommend you read the documentation in [OGGM Shop](https://docs.oggm.org/en/stable/shop.html). The model is currently configured to use Level 2 data with a border value of 40 m using elevation bands.  OGGM will automatically download the glacier directories based on the link you specify in the input file; however, if you would like to download them in advance (e.g., if your supercomputing environment does not allow you to access the internet within the script), then you may use the following as an example of how you can download these data to your local computer from OGGM’s server:\n",
    "\n",
    "```\n",
    "wget -r --no-parent https://cluster.klima.uni-bremen.de/~oggm/gdirs/oggm_v1.4/L1-L2_files/elev_bands/RGI62/b_240/L2/ \n",
    "```\n",
    "\n",
    "(climate_data_target)=\n",
    "## Climate Data (Reference)\n",
    "PyGEM requires a reference climate dataset, i.e., climate data that covers the calibration period. These data are provided as netcdf (.nc) files. The model is currently configured to use monthly data.\n",
    "\n",
    "For reference climate data (e.g., 2000-2020), PyGEM uses ERA5, which superseded ERA-Interim due to its higher resolution and other strengths. The following data is required with optional data noted accordingly:\n",
    "* Air temperature\n",
    "* Precipitation (total, i.e., liquid and solid)\n",
    "* Orography (geopotential)\n",
    "* Air temperature lapse rates\n",
    "* Air temperature daily standard deviation <em>(optional)</em>\n",
    "\n",
    "These data can be downloaded, or are derived from downloaded data, from the [Copernicus Climate Change Service (C3S) Climate Data Store](https://cds.climate.copernicus.eu/#!/search?text=ERA5&type=dataset). Instructions for downloading these climate data may be found [here](https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5). Specific detail on each dataset is provided below.\n",
    "\n",
    "### Monthly temperature\n",
    "Monthly near-surface (2 m) air temperature can be downloaded directly. This is used to calculate the positive degree days for melt, annual air temperature for refreezing, and to differentiate liquid and solid precipitation.\n",
    "\n",
    "### Monthly precipitation\n",
    "Monthly precipitation can be downloaded directly. This is used to calculate accumulation and runoff and is the total precipitation over the time period, which is currently monthly.\n",
    "\n",
    "### Orography\n",
    "Orography can be downloaded directly. This is used to account for elevation differences between the climate data pixel and the glaciers.\n",
    "\n",
    "### Lapse rates\n",
    "Monthly air temperature lapse rates are derived from monthly air temperature at each pressure level from 300 to 1000 hPa ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). The air temperature at various pressure levels can be downloaded and then processed using the 'createlapserates' option from **preprocess_ecmwf_data.py** in the **PyGEM-Scripts** respoitory. These lapse rates are used to adjust the air temperature for differences in elevations between the climate pixel and the glacier as well as for various elevation bins on the glacier.\n",
    "\n",
    "### Monthly temperature standard deviation\n",
    "Monthly air temperature standard deviation is an optional product, which is only required if you plan to account for the monthly temperature variations within ablation like was done in [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). These monthly data are derived from hourly near-surface air temperature. Hourly near-surface air temperature can be downloaded and processed using the 'createtempstd' option from **preprocess_ecmwf_data.py** in the **PyGEM-Scripts** respoitory. Note that the hourly data is quite large and therefore this step will take considerable time to download and process the data.\n",
    "\n",
    "## Climate Data (Future)\n",
    "The projected climate data has been developed using general circulation models (GCMs) from the Coupled Model Intercomparison Project Phase 5 (CMIP5), which uses Representative Concentration Pathways (RCPs) and CMIP Phase 6 (CMIP6), which uses Shared Socioeconomic Pathways (SSPs). While the use of RCPs may be of interest for comparison with previous studies, we recommend using SSPs moving forward.\n",
    "\n",
    "The climate data required is:\n",
    "* Air temperature\n",
    "* Precipitation\n",
    "* Orography\n",
    "\n",
    "These data are provided as netcdf (.nc) files and can be downloaded from [OGGM’s server](https://cluster.klima.uni-bremen.de/~oggm/). \n",
    "\n",
    "To account for differences between the reference and future climate data, bias adjustments are made to the future temperature and precipitation data. These are described in the [Section on Bias Corrections].\n",
    "\n",
    "(input_mb_data_target)=\n",
    "## Model Calibration and Validation Data\n",
    "The choice of calibration and validation data is entirely up to the modeler. However, PyGEM is currently configured to be calibrated with glacier-wide geodetic mass balance data and validated using glacier-wide glaciological data.\n",
    "\n",
    "### Calibration data\n",
    "Model parameters need to be calibrated and results should be validated using some form of mass balance (glaciological, geodetic, or gravimetric), glacier runoff, snowline, or equilibrium line altitude data ([Table 1](model_input_table_target)). Additional calibration data is required to account for frontal ablation associated with marine-terminating glaciers. We envision the model continuously incorporating new large-scale systematic datasets as they become available. \n",
    "\n",
    "The model was originally developed to integrate large-scale systematic glacier-wide mass balance data from 2000-2018 in High Mountain Asia [(Shean et al. 2020)](https://www.frontiersin.org/articles/10.3389/feart.2019.00363/full) and now uses a global dataset from 2000-2019 [(Hugonnet et al. 2021)](https://www.nature.com/articles/s41586-021-03436-z). The default frontal ablation data is currently from various datasets spanning 2000 to 2020 from the Northern Hemisphere [(Kochtitzky et al. 2022)](https://www.nature.com/articles/s41467-022-33231-x), South America [(Minowa et al. 2021)](https://www.sciencedirect.com/science/article/pii/S0012821X21000704), and Antarctica [(Osmanoglu et al. 2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014)](https://tc.copernicus.org/articles/8/1807/2014/). For model validation, annual and seasonal glaciological glacier-wide mass balance data from 1979 to 2019 have been used [(WGMS 2021)](https://wgms.ch/data_databaseversions/).\n",
    "\n",
    "The current file structure for both the geodetic and frontal ablation data are .csv files. It's important to enter all the relevant information within the “Calibration Datasets” section of **pygem_input.py**. The key information is the glacier's RGIId, mass balance in m water equivalent (w.e.) yr$^{-1}$, mass balance error/uncertainty, initial time, end time, and area of the glacier. Processing of these data for each glacier is done in the \"shop\" directory under the **mbdata.py** script. We recommend reviewing the sample mass balance data for additional information on file structure.\n",
    "\n",
    "### Validation data\n",
    "The model is currently developed to use glacier-wide annual and seasonal mass balance data for validation from the World Glacier Monitoring Service ([WGMS](https://wgms.ch/data_databaseversions/)).\n",
    "\n",
    "In addition to its use for model validation, the WGMS winter mass balance data is also used to constrain the initial calibration that is used to estimate the prior distributions for the Markov Chain Monte Carlo simulations. This processing is performed in **‘run_preprocessing_wgms_mbdata.py’** using the ‘-estimate_kp’ option.\n",
    "\n",
    "(input_debris_data_target)=\n",
    "## Debris Thickness Data\n",
    "For debris-covered glaciers, spatially distributed sub-debris melt enhancement factors are required. These files are provided by [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) as .tif files. There are currently scripts in the “shop” directory that process the .tif files and aggregate them to elevation bins to be consistent with the glacier directory structure of OGGM. If using a different dataset, this pre-processing would need to be added.\n",
    "\n",
    "(input_fa_data_target)=\n",
    "## Frontal Ablation Data\n",
    "The default frontal ablation data is currently from various datasets spanning 2000 to 2020 from the Northern Hemisphere ([Kochtitzky et al. 2022](https://www.nature.com/articles/s41467-022-33231-x)), South America ([Minowa et al. 2021](https://www.sciencedirect.com/science/article/pii/S0012821X21000704)), and Antarctic/Subantarctic ([Osmanoglu et al. 2013](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0); [2014](https://tc.copernicus.org/articles/8/1807/2014/)).\n",
    "\n",
    "(input_thickness_data_target)=\n",
    "## Ice Thickness Data\n",
    "The default ice thickness data is currently the \"consensus\" ice thickness estiamtes from [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3). These estimates are used to calibrate the ice viscosity parameter such that the modeled ice thickness estimates roughly match the \"consensus\" ice thickness estimates at a regional scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass Balance Models\n",
    "\n",
    "PyGEM computes the climatic mass balance for each elevation bin and timestep, estimates frontal ablation for marine-terminating glaciers at the end of each year (if this process is included), and updates the glacier geometry annually. The convention below follows [Cogley et al. (2011)](https://wgms.ch/downloads/Cogley_etal_2011.pdf). The total glacier-wide mass balance ($\\Delta M$) is thus estimated as:\n",
    "\n",
    "```{math}\n",
    "\\Delta M = B_{clim} + A_{f}/S\n",
    "```\n",
    "\n",
    "where $B_{clim}$ is the climatic mass balance in specific units, i.e. mass change per unit area (m w.e.), $A_{f}$ is frontal ablation, and $S$ is the glacier area. The basal mass balance is assumed to be zero.\n",
    "\n",
    "The climatic mass balance for each elevation bin ($b_{clim}$) is computed according to:\n",
    "```{math}\n",
    "b_{clim} = a + c + R\n",
    "```\n",
    "\n",
    "where $a$ is the ablation, $c$ is accumulation, and $R$ is refreezing (all in units of m w.e.). Mass loss is negative and mass gain is positive. The glacier-wide specific climatic mass balance ($B_{clim}$) is thus calculated by:\n",
    "```{math}\n",
    "\\sum_{i=1}^{nbins} b_{clim,i}\n",
    "```\n",
    "\n",
    "The model offers alternative methods for calculating the mass balance components and accounting for glacier geometry changes (i.e., representing glacier dynamics). These vary in level of complexity and computational expense. The current options for each component are described below:\n",
    "\n",
    "```{toctree}\n",
    "---\n",
    "caption: Mass Balance Components:\n",
    "maxdepth: 2\n",
    "---\n",
    "\n",
    "mb_ablation\n",
    "mb_accumulation\n",
    "mb_refreezing\n",
    "mb_frontalablation\n",
    "```\n",
    "\n",
    "## Summary of model parameters\n",
    "Below is a summary of some of the key mass balance model parameters, their symbols, units, and the values used in PyGEM. Note that some parameters are calculated, others are calibrated, and others may be specified by the user in the input file.\n",
    "\n",
    "| Parameter | Symbol | Unit | Value |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Ablation | $a$ | m w.e. | calculated |\n",
    "| Accumulation | $c$ | m w.e. | calculated |\n",
    "| Refreeze | $R$ | m w.e. | calculated |\n",
    "| Frontal ablation | $A_{f}$ | m w.e. | calculated |\n",
    "| Degree-day factor of snow | $f_{snow}$ | mm w.e. d$^{-1}$ K$^{-1}$ | calibrated |\n",
    "| Degree-day factor of ice | $f_{ice}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $f_{snow}$/0.7 <br>(user-specified) |\n",
    "| Degree-day factor of firn | $f_{firn}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $\\frac{f_{snow}+f_{ice}}{2}$ |\n",
    "| Degree-day factor of debris | $f_{debris}$ | mm w.e. d$^{-1}$ K$^{-1}$ | $E_{d} \\cdot f_{ice}$ |\n",
    "| Sub-debris melt enhancement factor | $E_{d}$ | - | 1 if no debris; <br> otherwise from [Rounce et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) |\n",
    "| Temperature bias correction | $T_{bias}$ | K | calibrated |\n",
    "| Threshold temperature (rain/snow) | $T_{snow}$ | $^{\\circ}$C | 1 <br> (user-specified) |\n",
    "| Precipitation correction factor | $k_{p}$ | - | calibrated |\n",
    "| Precipitation gradient | $d_{prec}$ | m$^{-1}$ | 0.0001 <br> (user-specified) |\n",
    "| Frontal ablation scaling parameter | $k$ | yr$^{-1}$ | calibrated |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation\n",
    "There are currently two model options for ablation. Both model options use a degree-day model ($f$). \n",
    "\n",
    "### Option 1: monthly temperatures\n",
    "The first calculates ablation ($a$) using the mean monthly temperature:\n",
    "$$a=f_{snow/ice/firn/debris} \\cdot T_{m}^{+} \\cdot n$$\n",
    "\n",
    "where $f$ is the degree-day factor of snow, ice, firn, or debris (m w.e. d-1 °C$^{-1}$), $T_{m}^{+}$ is the positive monthly mean temperature (°C), and $n$ is the number of days per month. \n",
    "\n",
    "### Option 2: monthly temperatures with daily variance\n",
    "The second option incorporates the daily variance associated with the temperature for each month according to [Huss and Hock (2015)]((https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)):\n",
    "$$a=f_{snow/ice/firn/debris} \\cdot \\sum_{i=1}^{ndays} T_{d,i}^{+} $$\n",
    "\n",
    "where $T_{d}$ is the daily positive mean air temperature and is estimated by superimposing random variability from the standard deviation of the daily temperature for each month.\n",
    "\n",
    "The degree-day factors for snow, ice, firn, and debris depend on the surface type option that is chosen by the user (see Section 5). The values of $f$ for these various surface types are assumed to be related to one another to reduce the number of model parameters. The default ratio of the $f_{snow}$ to the $f_{ice}$ is 0.7, and $f_{firn}$ is assumed to be the mean of the $f_{snow}$ and $f_{ice}$; however, the user may change these values in the input file if desired. The values for $f_{debris}$ are equal to $f_{ice}$ multiplied by the mean sub-debris melt enhancement factor [(Rounce et al. 2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2020GL091311) for the given elevation bin.\n",
    "\n",
    "### Temperature at elevation bins\n",
    "Temperature for each elevation bin ($T_{bin}$) is determined by selecting the temperature from the gridded climate data ($T_{gcm}$) based on the nearest neighbor, which is then downscaled to the elevation bins on the glacier according to:\n",
    "$$T_{bin} = T_{gcm} + lr_{gcm} \\cdot (z_{ref} - z_{gcm}) + lr_{glac} \\cdot (z_{bin} - z_{ref}) + T_{bias}$$\n",
    "\n",
    "where $lr_{gcm}$ and $lr_{glac}$ are lapse rates (°C m-1) associated with downscaling the climate data to the glacier and then over the glacier elevation bins, respectively; $z_{ref}$, $z_{gcm}$, and $z_{bin}$ are the elevations from the glacier’s reference point (median or mean elevation), the climate data, and the elevation bin, respectively; and $T_{bias}$ is the temperature bias. The temperature bias is one of three model parameters that is calibrated and serves to account for any biases resulting from the use of coarse climate data that is unable to capture local topographic variations. By default, the $lr_{gcm}$ and $lr_{glac}$ are assumed to be equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulation\n",
    "Accumulation ($c$) is calculated for each elevation bin as a function of the precipitation ($P_{bin}$), air temperature ($T_{bin}$), and the snow temperature threshold ($T_{snow}$).  There are two options for estimating accumulation based on how to classify precipitation as liquid or solid. \n",
    "\n",
    "### Option 1: Threshold +/- 1$^{\\circ}$C\n",
    "The first (default) option is to estimate the ratio of liquid and solid precipitation based on the air temperature:\n",
    "$$c = \\delta \\cdot P_{bin}$$\n",
    "\n",
    "where $\\delta=1$; if $T_{bin} \\leq T_{snow}-1$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\delta=0$; if $T_{bin} \\geq T_{snow}+1$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\delta=0.5-(T_{bin}-T_{snow})/2$; if $T_{snow}-1 < T_{bin} < T_{snow}+1$\n",
    "\n",
    "<br>where $P_{bin}$ is the monthly precipitation and $\\delta$ is the fraction of solid precipitation each month. $T_{snow}$ typically ranges from 0 – 2 $^{\\circ}$C ([Radić and Hock, 2011](https://www.nature.com/articles/ngeo1052); [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)) and is typically assumed to be 1$^{\\circ}$C.  \n",
    "\n",
    "### Option 2: Single threshold\n",
    "The alternative option is to classify precipitation as snow or rain based on a single threshold.\n",
    "\n",
    "### Precipitation at elevation bins\n",
    "Precipitation at each elevation bin of the glacier ($P_{bin}$) is determined by selecting the precipitation from the gridded climate data ($P_{gcm}$) based on the nearest neighbor, which is then downscaled to the elevation bins on the glacier:\n",
    "$$P_{bin} = P_{GCM} \\cdot k_{p} \\cdot (1 + d_{prec} \\cdot (z_{bin} - z_{ref}))$$\n",
    "<br>where $k_{p}$ is the precipitation factor and $d_{prec}$ is the precipitation gradient. The precipitation factor is a model parameter that is used to adjust from the climate data to the glacier, which could be caused by local topographic effects due to differences in elevation, rain shadow effects, etc. The precipitation gradient is another model parameter, which is used to redistribute the precipitation along the glacier and can be thought of as a precipitation lapse rate. Typical values for the precipitation gradient vary from 0.01 – 0.025% m$^{-1}$([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) who cited [WGMS, 2012](https://wgms.ch/products_fog/)). The default assumes a precipitation gradient of 0.01% m$^{-1}$ to reduce the number of model parameters.\n",
    "\n",
    "Additionally, for glaciers with high relief (> 1000 m), the precipitation in the uppermost 25% of the glacier’s elevation is reduced using an exponential function ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)):\n",
    "$$P_{bin,exp} = P_{bin} \\cdot exp(\\frac{z_{bin} - z_{75\\%}}{z_{max} - z_{75\\%}}) $$\n",
    "where $P_{bin,exp}$ is the adjusted precipitation, and $z_{max}$ and $z_{75\\%}$ are the elevation of the glacier maximum and the glacier’s 75th percentile elevation, respectively. The adjusted precipitation cannot be lower than 87.5% of the maximum precipitation on the glacier. This adjustment accounts for the reduced air moisture and increased wind erosion at higher elevations ([Benn and Lehmkuhl, 2000](https://risweb.st-andrews.ac.uk/portal/en/researchoutput/mass-balance-and-equilibriumline-altitudes-of-glaciers-in-highmountain-environments(080f17fc-33dd-4805-bc97-a5aaa018a457)/export.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refreezing\n",
    "There are two model options for computing refreezing.  The default option estimates refreezing based on the mean annual air temperature ([Woodward et al. 1997](https://www.cambridge.org/core/journals/annals-of-glaciology/article/influence-of-superimposedice-formation-on-the-sensitivity-of-glacier-mass-balance-to-climate-change/84DFA08E9CC8F28BE0729F1EBF4DA4E1)), while the alternative is based on heat conduction ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)).\n",
    "\n",
    "### Option 1: Mean annual air temperature\n",
    "For the default option, refreezing (R) is calculated for each elevation bin as a function of its weighted annual mean air temperature (Ta) following [Woodward et al. (1997)](https://www.cambridge.org/core/journals/annals-of-glaciology/article/influence-of-superimposedice-formation-on-the-sensitivity-of-glacier-mass-balance-to-climate-change/84DFA08E9CC8F28BE0729F1EBF4DA4E1)):\n",
    "$$R = -0.0069 \\cdot T_{a} + 0.000096$$\n",
    "The weighted annual mean accounts for the number of days in each month. Refreezing cannot be negative. The model assumes that refreezing occurs in the snowpack as opposed to being superimposed ice, so in the ablation zone the refreezing cannot exceed the snow depth. Since this option estimates annual refreezing, the equation above provides the maximum amount of potential refreezing. Each year, the potential refreezing is reset in October as this is the transition season from predominantly summer melt to winter accumulation. Therefore, it is possible that accumulated snow may melt and refreeze diurnally. The model replicates this physical behavior by first determining the amount of snow that has melted in that month. If the refreezing potential is greater than zero, the model assumes the snow melts and refreezes in the snow pack. Refreezing cannot exceed the amount of snow melt in any given month. The amount of refreezing is then subtracted from the potential refreezing until the potential refreezing is fully depleted or reset. Once the snow and refreezing completely melts, the model can melt the underlying ice/firn/snow.  This model is used as the default because it is computationally cheap compared to the alternative.\n",
    "\n",
    "### Option 2: Heat conduction\n",
    "The alternative option is to estimate refreezing using modeled snow and firn temperatures based on heat conduction as described by [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). This option is significantly more computationally expensive. The code for this section was translated from the IDL code used in [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full), which potentially has an error in the heat conduction equation where the temperature in each layer is divided by a factor of 2 that Lilian Schuster identified is not physically-derived (as of 2021 - this error has not been fixed). This option should thus be used with caution until further developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontal Ablation\n",
    "For marine-terminating glaciers, frontal ablation is modeled using a frontal ablation parameterization coupled to the ice dynamical model (i.e., the glacier dynamics parameterization). Given the coupling to the dynamical model, frontal ablation is accounted for on an annual timestep and the code for the frontal ablation parameterization is located with the dynamical model. OGGM provides a nice overview of the frontal ablation parameterization in one of their advanced tutorials:\n",
    "\n",
    "https://oggm.org/tutorials/stable/notebooks/kcalving_parameterization.html\n",
    "\n",
    "The same parameterization is included for mass redistribution curves in PyGEM.\n",
    "\n",
    "Frontal ablation ($A_{f}$) computes the mass that is removed at the glacier front when the bedrock is below sea level using an empirical formula following [Oerlemans and Nick (2005)](https://www.cambridge.org/core/journals/annals-of-glaciology/article/minimal-model-of-a-tidewater-glacier/C6B72F547D8C44CDAAAD337E1F2FC97F):\n",
    "$$A_{f} = k \\cdot d \\cdot H_{f} \\cdot w$$\n",
    "where $k$ is the frontal ablation scaling parameter (yr$^{-1}$), $d$ is the water depth at the calving front (m), $H_{f}$ is the ice thickness at the calving front, and $w$ is the glacier width at the calving front. Over the next century, many marine-terminating glaciers are projected to retreat onto land based on present-day frontal ablation rates ([Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324)); hence, the maximum frontal ablation rate is constrained by the mass of ice where the bed elevation of the bin is located below sea level. The user is also able to specify the water level (default is 0), which supports the application of the parameterization to lake-terminating glaciers in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier Dynamics\n",
    "Glacier dynamics in large-scale glacier evolution models typically rely on geometry changes like volume-area-length scaling (e.g., [Radić and Hock, 2011](https://www.nature.com/articles/ngeo1052)), mass redistribution using empirical equations (e.g., [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)), or simplified glacier dynamics (e.g., [Maussion et al., 2019](https://gmd.copernicus.org/articles/12/909/2019/)). [Zekollari et al. (2022)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021RG000754) provide a comprehensive review of ice dynamics for mountain glaciers. These methods all allow the glacier to evolve over time in response to the total glacier-wide mass balance. The benefit of volume-area-length scaling and mass redistribution is they are computationally inexpensive compared to simplified glacier dynamics methods. The two options available in PyGEM are OGGM’s flowline model using the shallow ice approximation ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)) and mass redistribution curves ([Rounce et al. 2020](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)).\n",
    "\n",
    "## Option 1: OGGM flowline model using shallow-ice approximation\n",
    "PyGEM has been developed to be compatible with OGGM thereby enabling the use of their ice dynamics flowline model ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)). The model uses a shallow ice approximation with a depth-integrated flowline model to explicitly compute the flux of ice along the glacier centerline. Model details are fully documented in OGGM’s manual found [here](https://docs.oggm.org/en/latest/ice-dynamics.html).\n",
    "\n",
    "(mass_redistribution_curves_target)=\n",
    "## Option 2: Mass redistribution curves\n",
    "The mass redistribution curves in PyGEM follow those developed by [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) based on [Huss et al. (2010)](https://hess.copernicus.org/articles/14/815/2010/hess-14-815-2010.html) but explicitly solve for area and ice thickness changes simultaneously to conserve mass. The approach is only applied to glaciers that have at least three elevation bins. Each year the glacier-wide mass balance is computed (see Mass Balance Section) and the mass is redistributed over the glacier using empirical equations that set the normalized surface elevation change ($\\Delta h$) as a function of the glacier’s elevation bins:\n",
    "$$\\Delta h = (h_{n} + a_{HH2015})^{\\gamma} + b_{HH2015} \\cdot (h_{n} + a_{HH2015}) + c_{HH2015} $$\n",
    "where $h_{n}$ is the normalized elevation according to $\\frac{z_{max} - z_{bin}}{z_{max} - z_{min}}$ and $a_{HH2015)$, $b_{HH2015)$, $c_{HH2015)$, and $\\gamma$ are all calibrated coefficients based on 34 glaciers in the Swiss Alps. These coefficients vary depending on the size of the glacier ([Huss et al., 2010]((https://hess.copernicus.org/articles/14/815/2010/hess-14-815-2010.html))). In order to ensure that mass is conserved, i.e., the integration of the elevation change and glacier area (A) of each bin over all the elevation bins ($nbins$) is equal to the glacier-wide volume change ($\\Delta V$), an ice thickness scaling factor ($f_{s,HH2015}$) must be computed:\n",
    "$$f_{s,HH2015} = \\frac{\\Delta V}{\\sum_{i=0}^{nbins} A_{i} \\cdot \\Delta h_{i}} $$\n",
    "The volume change in each elevation bin ($\\Delta V_{bin}$) is computed as:\n",
    "$$\\Delta V_{bin} = f_{s,HH2015} \\cdot \\Delta h_{bin} \\cdot A_{bin} $$\n",
    "Depending on the bed shape (parabolic, triangular or rectangular) of the glacier, the resulting area, ice thickness ($H$), and width ($W$) can be solved for explicitly based on mass conservation and the use of similar shapes:\n",
    "$$H_{bin,t+1} \\cdot A_{bin,t+1} = H_{bin,t} \\cdot A_{bin,t} + \\Delta V_{bin} $$\n",
    "$$\\frac{H_{bin,t+1}}{H_{bin,t}} \\alpha \\frac{A_{bin,t+1}}{A_bin,t} $$\n",
    "This is a marked improvement over previous studies that have not explicitly solved for the area and ice thickness changes simultaneously, which can lead to mass loss or gain that is then corrected ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)).\n",
    "\n",
    "### Glacier retreat\n",
    "Glacier retreat occurs when the volume change in an elevation bin ($\\Delta V_{bin}$) causes the ice thickness for the next time step to be less than zero. In this case, the ice thickness is set to zero and the remaining volume change is redistributed over the entire glacier according to the mass redistribution described above. \n",
    "\n",
    "### Glacier advance\n",
    "Glacier advance occurs when the ice thickness change exceeds the ice thickness advance threshold (default: 5 m; [Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). When this occurs, the ice thickness change is set to 5 m, the area and width of the bin are calculated accordingly, and the excess volume is recorded. The model then calculates the average area and thickness associated with the bins located in the glacier’s terminus, which is defined by the terminus percentage (default: 20%). However, this calculation excludes the bin actually located at the terminus because prior to adding a new elevation bin, the model checks that the bin located at the terminus is “full”. Specifically, the area and ice thickness of the lowermost bin are compared to the terminus’ average and if the area and ice thickness is less than the average, then the lowermost bin is first filled until it reaches the terminus average. This ensures that the lowermost bin is “full” and prevents adding new bins to a glacier that may only have a relatively small excess volume in consecutive years. In other words, if this criterion did not exist, then it would be possible to add new bins over multiple years that had small areas, which would appear as though the glacier was moving down a steep slope.\n",
    "\n",
    "If there is still excess volume remaining after filling the lowermost bin to the terminus average, then a new bin is added below the terminus. The ice thickness in this new bin is set to be equal to the terminus average and the area is computed based on the excess volume. If the area of this bin would be greater than the average area of the terminus, this indicates that an additional bin needs to be added. However, prior to adding an additional bin the excess volume is redistributed over the glacier again. This allows the glacier’s area and thickness to increase and prevents the glacier from having a thin layer of ice that advances down-valley without thickening.\n",
    "\n",
    "There are two exceptions for when a glacier is not allowed to advance to a particular bin. The first exception is if the added bin would be below sea-level, in which case the remaining excess volume is redistributed over the entire glacier. The second exception is if the bin is over a known discontinuous section of the glacier, which is determined based on the initial glacier area. For example, it is possible, albeit unlikely, that a glacier could retreat over a discontinuous section of a glacier and then advance in the future. This discontinuous area is assumed to be a steep vertical drop, hence why a glacier currently does not exist, so a glacier is not allowed to form there in the future. The glacier instead skips over this discontinuous bin and a new bin is added below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glacier Runoff\n",
    "Following [Huss and Hock (2018)](https://www.nature.com/articles/s41558-017-0049-x), glacier runoff ($Q$) is defined as all water that leaves the initial glacierized area, which includes rain ($P_{liquid}$), ablation ($a$), and refreezing ($R$) as follows:\n",
    "\n",
    "```{math}\n",
    "Q = P_{liquid} + a - R\n",
    "```\n",
    "\n",
    "In the case of glacier retreat, rain, snow melt, and refreezing are computed for the non-glaciated portion of the initial glacier area and this runoff is referred to as “off-glacier” runoff. No other processes, e.g., evapotranspiration or groundwater recharge, are accounted for in these deglaciated areas. \n",
    "\n",
    "```{warning}\n",
    "In the case of glacier advance, runoff is computed over the current year’s glacier area, which may exceed the initial glacierized area. Given that most glaciers are retreating, the increase in glacier runoff due to the additional glacier area is considered to be negligible.\n",
    "```\n",
    "\n",
    "Excess meltwater is defined as the runoff caused by glacier mass loss that the glacier does not regain over the duration of the entire simulated period (**Figure 1**). For example, a glacier that melts completely contributes its entire mass as excess meltwater, while a glacier in equilibrium produces no excess meltwater. Since interannual glacier mass change is highly variable, i.e., a glacier can lose, gain, and then lose mass again, excess meltwater is computed retroactively as the last time that the glacier mass is lost.\n",
    "\n",
    "```{figure} _static/excess_meltwater_diagram.png\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "```\n",
    "\n",
    "**Figure 1.** Diagram exemplifying how excess meltwater (blue dashed line) is calculated retroactively based on annual glacier mass balance (black line) over time. Cumulative (top subplot) and annual (bottom subplot) mass balance and excess meltwater are shown. Years refer to mass-balance years and values of cumulative mass balances and excess meltwater refer to the end of each mass-balance year. The total excess meltwater is equivalent to the total mass loss over the entire period, and therefore is not equal to the absolute sum of all annual negative mass balances if positive mass balances have occurred in the period. Excess meltwater is distributed retroactively over all mass-balance years that are negative and where the lost mass is not regained in the future. For example, annual mass balances in year 6, 7 and 9 are negative, but all mass loss lost between year 6 and 10 is regained by the end of year 10; thus, excess meltwater is zero in years 6 to 10 despite negative annual mass balances. Excess meltwater for any year with negative mass balance cannot exceed the annual net mass loss of that year. The figure is copied from [Rounce et al. (2020)](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Corrections\n",
    "Bias corrections can be applied to ensure the temperature and precipitation associated with the future climate data is roughly consistent with the reference climate data. \n",
    "\n",
    "## Delta change\n",
    "The temperature bias corrections follow [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) and use an additive factor to ensure the mean monthly temperature and interannual monthly variability are consistent between the reference and future climate data. \n",
    "\n",
    "There are two options for the precipitation bias correction:\n",
    "\n",
    "**Option 2** follows [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) and uses a multiplicative factor to ensure the monthly mean precipitation are consistent between the reference and future climate data. \n",
    "\n",
    "**Option 1** modifies the approach of [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full), since in dry regions, the adjusted precipitation was found to be unrealistically high when using multiplicative values. This option uses the interannual monthly variability and quality controls the bias corrected precipitation by replacing any values that exceed the monthly maximum with the monthly average adjusted for potentially wetter years in the future using the normalized annual variation. Note that [Marzeion et al. (2020)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EF001470) suggests that [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) have updated their approach to also adjust the precipitation bias correction to account for monthly interannual variability as well.\n",
    "\n",
    "## Quantile delta mapping\n",
    "The temperature and precipitation bias corrections follow the approach below:\n",
    "\n",
    "**Option 3** follows [Lader et al. (2017)](https://journals.ametsoc.org/view/journals/apme/56/9/jamc-d-16-0415.1.xml) and uses a quantile delta mapping approach to capture both the future mean climate and future climatic extremes. This option determines the relative change between the future and historical simulated climate data at each percentile in the distribution and overlays the difference onto the reference dataset. For example, the 70th-percentile precipitation from a simulated future distribution is divided by the 70th-percentile precipitation from the simulated historic distribution to calculate the modeled ratio of change. This ratio is then multiplied by the 70th-percentile precipitation from the reference dataset to calculate the bias-corrected future value. This is applied in 20-year increments (e.g., 2020-2040, 2040-2060) to better represent the changing climate over time.\n",
    "\n",
    "```{note}\n",
    "These bias corrections significantly impact projections for all glacier evolution models. Current work is thus investigating different bias corrections and how they affect projections. We hope to add additional bias correction options in the near future.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Conditions and Surface Type\n",
    "Initial glacier area is based on the RGI and assumed to represent the year 2000.  The initial surface type is based on the glacier’s median elevation, with the higher elevation being classified as firn and the lower classified as ice (or debris-covered). The surface type evolves based on the five-year running average of the glacier bin’s annual climatic mass balance ([Huss and Hock, 2015](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full)). If the five running average is positive, then the surface is classified as firn, while if it is negative, the surface is classified as ice. The surface type is classified as snow when snow accumulates on the surface.\n",
    "\n",
    "During the ice thickness inversion, which is done using OGGM ([Maussion et al. 2019](https://gmd.copernicus.org/articles/12/909/2019/)), the glacier is assumed to be in steady state. As a result, at the start of the simulation, there is typically a dynamical adjustment as the ice thickness is redistributed in response to the climatic mass balance forcing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(calibration_target)=\n",
    "# Model Calibration\n",
    "Several calibration options exist, which vary with respect to complexity and computational expense. These include the relatively straightforward approach of [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full), which is referred to as ‘HH2015’ to more complex Bayesian approaches from [Rounce et al. (2023)](https://www.science.org/doi/10.1126/science.abo1324) (‘MCMC’) ([Table 1](cal_options_table_target). At present, the options all use geodetic glacier-wide mass balance data for each glacier in units of meters of water equivalent (m w.e.) per year ([Hugonnet et al. 2021]((https://www.nature.com/articles/s41586-021-03436-z)). The calibration is done assuming the glacier area remains constant to avoid mass balance-ice thickness circularity issues.\n",
    "\n",
    "(cal_options_table_target)=\n",
    "\n",
    "| Calibration option | Overview | Reference |\n",
    "| :--- | :--- | :--- |\n",
    "| ['HH2015'](HH2015_target) | Finds single set of parameters.<br>Varies in order: $f_{snow}$, $k_{p}$, $T_{bias}$ | [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) |\n",
    "| ['HH2015mod'](HH2015mod_target) | Finds single set of parameters.<br>Varies in order: $k_{p}$, $T_{bias}$ | [Rounce et al. 2020](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432) |\n",
    "| ['emulator'](emulator_target) | Creates emulator for ['MCMC'](MCMC_target).<br>Finds single set of parameters with emulator following ['HH2015mod'](HH2015mod_target) | [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324) |\n",
    "| ['MCMC'](MCMC_target) | Finds multiple sets of parameters using Bayesian inference with [emulator](emulator_target).<br> Varies $f_{snow}$, $k_{p}$, $T_{bias}$ | [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324) |\n",
    "| ['MCMC_fullsim'](MCMC_target) | Finds multiple sets of parameters using Bayesian inference with full model simulations.<br> Varies $f_{snow}$, $k_{p}$, $T_{bias}$ | [Rounce et al. 2020](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432) |\n",
    "| [Future options](cal_custom_target) | Stay tuned for new options coming in 2023/2024! | | \n",
    "\n",
    "The output of each calibration is a .pkl file that holds a dictionary of the calibration options and the subsequent model parameters.  Thus, the .pkl file will store several calibration options.  Each calibration option is a key to the dictionary. The model parameters are also stored in a dictionary (i.e., a dictionary within a dictionary) with each model parameter being a key to the dictionary that provides access to a list of values for that specific model parameter. The following shows an example of how to print a list of the precipitation factors ($k_{p}$) for the calibration option specified in the input file:\n",
    "\n",
    "```\n",
    "with open(modelprms_fullfn, 'rb') as f:\n",
    "    modelprms_dict = pickle.load(f)\n",
    "print(modelprms_dict[pygem_prms.option_calibration][‘kp’])\n",
    "```\n",
    "\n",
    "The calibration options are each discussed below.  We recommend using the MCMC calibration option (Rounce et al. [2020a](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432), [2020b](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full), [2023](https://www.science.org/doi/10.1126/science.abo1324)) as this enables the user to quantify the uncertainty associated with the model parameters in the simulations; however, it is very computationally expensive. The methods from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) provide a computationally cheap alternative. \n",
    "\n",
    "```{note}\n",
    "Running these options is performed using **run_calibration.py** (see [Model Workflow](workflow_cal_prms_target)). Additionally, there are two other calibration scripts to calibrate the [ice viscosity model parameter](workflow_cal_glena_target) using the **run_calibration_icethickness_consensus.py** and the [frontal ablation parameter](calibration_frontalablation_target) for marine-terminating glaciers using the **run_calibration_frontalablation.py**.\n",
    "```\n",
    "\n",
    "(HH2015_target)=\n",
    "## HH2015\n",
    "The calibration option **‘HH2015’** follows the calibration steps from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full). Specifically, the precipitation factor is initially adjusted between 0.8-2.0. If agreement between the observed and modeled mass balance is not reached, then the degree-day factor of snow is adjusted between 1.75-4.5 mm d$^{-1}$ K$^{-1}$. Note that the ratio of the degree-day factor of ice to snow is set to 2, so both parameters are adjusted simultaneously. Lastly, if agreement is still not achieved, then the temperature bias is adjusted.\n",
    "\n",
    "(HH2015mod_target)=\n",
    "## HH2015mod\n",
    "The calibration option **‘HH2015mod’** is a modification of the calibration steps from [Huss and Hock (2015)](https://www.frontiersin.org/articles/10.3389/feart.2015.00054/full) that are used to generate the prior distributions for the MCMC methods [(Rounce et al. 2020a)](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432)\n",
    ". Since the MCMC methods used degree-day factors of snow based on previous studies, only the precipitation factor and temperature bias are calibrated. The precipitation factor varies from 0.5-3 and if agreement is not reached between the observed and modeled mass balance, then the temperature bias is varied. Note the limits on the precipitation factor are estimated based on a rough estimate of the precipitation factors needed for the modeled winter mass balance of reference glacier to match the observations.\n",
    "\n",
    "However, if you plan to use the MCMC methods, you are suggested to use the **‘emulator’** calibration option described below, which follows the same steps, but creates an emulator to run the mass balance simulations for each potential parameter set to reduce the computational expense.\n",
    "\n",
    "(emulator_target)=\n",
    "## Emulator applying HH2015mod\n",
    "The calibration option **‘emulator’** creates an independent emulator for each glacier that is derived by performing 100 present-day simulations based on randomly sampled model parameter sets and then fitting a Gaussian Process to these parameter-response pairs. This model replaces the mass balance model within the MCMC sampler (see Bayesian inference using MCMC below), which tests showed reduces the computational expense by two orders of magnitude. In the event that a single set of model parameters is desired, the emulator is also used to derive a set of model parameters following the same steps as ‘HH2015mod’.\n",
    "\n",
    "```{note}\n",
    "The ‘emulator’ calibration option will generate both the .pkl file of the model parmaters as well as the model simulations and emulators for each glacier stored in a subdirectory named 'emulator'.\n",
    "```\n",
    "\n",
    "```{note}\n",
    "The ‘emulator’ calibration option needs to be run before the ‘MCMC’ option.\n",
    "```\n",
    "\n",
    "(MCMC_target)=\n",
    "## Bayesian inference using Markov Chain Monte Carlo methods\n",
    "The calibration option **‘MCMC’** is the recommended option. Details of the methods are provided by Rounce et al. ([2020a](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432), [2023](https://www.science.org/doi/10.1126/science.abo1324)). In short, Bayesian inference is performed using Markov Chain Monte Carlo (MCMC) methods, which requires a mass balance observation (including the uncertainty represented by a standard deviation) and prior distributions. In an ideal world, we would have enough data to use broad prior distributions (e.g., uniform distributions), but unfortunately the model is overparameterized meaning there are an infinite number of parameter sets that give us a perfect fit. We therefore must use an empirical Bayes approach by which we use a simple optimization scheme (the **‘HH2015mod’** calibration option) to generate our prior distributions at the regional scale, and then use these prior distributions for the Bayesian inference. The prior distribution for the degree-day factor is based on previous data ([Braithwaite 2008](https://www.cambridge.org/core/journals/journal-of-glaciology/article/temperature-and-precipitation-climate-at-the-equilibriumline-altitude-of-glaciers-expressed-by-the-degreeday-factor-for-melting-snow/6C2362F61B7DE7F153247A039736D54C)), while the temperature bias and precipitation factor are derived using a simple optimization scheme based on each RGI Order 2 subregion. The temperature bias assumes a normal distribution and the precipitation factor assumes a gamma distribution to ensure positivity. Glacier-wide winter mass balance data ([WGMS 2020](https://wgms.ch/data_databaseversions/)) are used to determine a reasonable upper-level constraint for the precipitation factor for the simple optimization scheme.\n",
    "\n",
    "The MCMC methods thus require several steps. First, set the <em>option_calibration = ‘emulator’</em> in **pygem_input.py**. This creates an emulator that helps speed up the simulations within the MCMC methods and helps generate an initial calibration to generate the regional priors. Run this initial calibration:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "The regional priors are then determined by running the following:\n",
    "```\n",
    "python run_mcmc_prior.py\n",
    "```\n",
    "This will output a .csv file that has the distributions for the temperature bias and precipitation factors for each Order 2 RGI subregion. This file is located in the calibration subdirectory within the Output directory.\n",
    "\n",
    "Once the regional priors are set, the MCMC methods can be performed.  Change the <em>option_calibration = ‘MCMC’</em> in **pygem_input.py**, then run the following:\n",
    "```\n",
    "python run_calibration.py\n",
    "```\n",
    "In order to reduce the file size, the parameter sets are thinned by a factor of 10. This is reasonable given the correlation between subsequent parameter sets during the Markov Chain, but can be adjusted if thinning is not desired (change value to 1 in the input file).\n",
    "\n",
    "```{note}\n",
    "**'MCMC_fullsim'** is another calibration option that runs full model simulations within the MCMC methods instead of using the emulator. It is computationally very expensive but allows one to assess the emulators impact on the MCMC methods.\n",
    "```\n",
    "\n",
    "(cal_custom_target)=\n",
    "## Customized Calibration Routines\n",
    "As new observations become available, we envision the calibration routines will need to change to leverage these observations. The only real limitation in developing a calibration routine is that the dictionary stored as a .pkl file needs to be consistent such that the calibration option is consistent with the run_simulation.py script.\n",
    "\n",
    "(calibration_frontalablation_target)=\n",
    "## Frontal Ablation Parameter for Marine-terminating Glaciers\n",
    "Marine-terminating glaciers have an additional frontal ablation parameter that is calibrated at the glacier-scale to match frontal ablation data [(Osmanoglu et al. 2013;](https://www.cambridge.org/core/journals/annals-of-glaciology/article/surface-velocity-and-ice-discharge-of-the-ice-cap-on-king-george-island-antarctica/62E511405ADD31A43FF52CDBC727A9D0) [2014;](https://tc.copernicus.org/articles/8/1807/2014/) [Minowa et al. 2021;](https://www.sciencedirect.com/science/article/pii/S0012821X21000704) [Kochtitzky et al. 2022](https://www.nature.com/articles/s41467-022-33231-x)). Marine-terminating glaciers require a special procedure for calibration to avoid circularity issues. The initial ice thickness is estimated using the mass balance parameters assuming the glacier is land-terminating and a forward simulation from 2000-2020 estimates the frontal ablation. If a dynamic instability error occurs (8% of glaciers for [Rounce et al. 2023](https://www.science.org/doi/10.1126/science.abo1324)), the glacier dynamics model uses [mass redistribution curves](mass_redistribution_curves_target) instead. For quality control, we combined the frontal ablation and geodetic mass balance observations to estimate climatic mass balances. For some glaciers, the resulting climatic mass balances are unrealistic due to errors in the RGI outlines and/or poor glacier thickness and velocity data used in frontal ablation calculations. For these glaciers, we assume frontal ablation is overestimated and reduce the frontal ablation to ensure the climatic mass balance is within three standard deviations of the regional mean from the geodetic mass balance data. The Antarctic and Subantarctic have the sparsest frontal ablation data, so the region’s median frontal ablation parameter and corresponding standard deviation is used for glaciers without data.\n",
    "\n",
    "The frontal ablation calibration is a hard-coded script that requires several steps. First, you need to change the region within the run_calibration_frontalablation.py script. Then merge the frontal ablation data together into a single directory:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_data = True)\n",
    "```\n",
    "Followed by calibrating the frontal ablation parameter for each marine-terminating glacier:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_ind_calving_k = True)\n",
    "```\n",
    "Then merge all the frontal ablation parameters into a single file:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_calving_k = True)\n",
    "```\n",
    "Lastly, update the climatic-basal mass balance data by removing the frontal ablation from the total mass change:\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_update_mb_data = True)\n",
    "```\n",
    "```{note}\n",
    "The run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. \n",
    "```\n",
    "\n",
    "## Ice Viscosity Parameter\n",
    "The ice viscosity parameter will affect the ice thickness inversion and dynamical evolution of the glacier. The ice viscosity parameter is currently calibrated such that the volume of ice at the regional scale is consistent with the regional ice volumes from [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "While PyGEM has a number of strengths, we also want to be transparent of several limitations that the current version has:\n",
    "* **Monthly timestep**: while we plan to add the option to use daily data in the future, the model is currently only set up for monthly timesteps.\n",
    "* **ERA5 climate data**: we currently use ERA5 data as our reference data and this is the only dataset that PyGEM currently supports. We are aware of recent studies that have shown reanalysis precipitation data have issues compared to other data (Alexander et al. 2020) and may consider alternative precipitation data in the future.  The class_climate.py script can be modified to incorporate others.\n",
    "* **Geodetic mass balance data**: while we envision adding options to incorporate other datasets (e.g., multiple mass balance datasets, mass balance gradients, snowline altitudes) for model calibration, the current framework is set up for a single glacier-wide mass balance observation for each glacier. Note that the geodetic mass balance data requires the time period to be specific with each observation; however, the time period does not have to be the same for each glacier.\n",
    "* **Glacier-specific workflow**: the model requires mass balance data for each glacier for model calibration. We hope to incorporate regional data as well in the future.\n",
    "* **Off-glacier snow accumulation**: when the glacier retreats, the model continues to compute accumulation, melt, and refreeze of snow over the deglaciated area. Glacier retreat may create off-glacier areas at high altitudes. At high altitudes, it’s possible for the temperature to be negative year-round and thereby cause off-glacier snow to accumulate unrealistically over time. Potential solutions could include removing the snow each year assuming that it sublimates, developing an avalanche parameterization to add the snow onto the glacier, or an alternative we have not yet considered. It is good to be aware of this since snow at this elevation will not contribute to off-glacier runoff since it doesn’t melt.\n",
    "* **Runoff for advancing glaciers**: when the glacier advances, the model continues to compute the runoff over the entire glacier area, which may exceed the initial glacierized area.\n",
    "* **Initialization at 2000**: the RGI is used to initialize the glacier areas. While the RGI targets all glacier extents to be from 2000, this may significantly vary depending on the source of the data. We assume the glacier extents represent 2000 and do not correct for these issues.\n",
    "* **Mass balance-ice thickness circularity issues**: circular issues exist regarding the derivation of the mass balance gradient and the ice thickness, i.e., a mass balance gradient is needed to estimate the ice thickness and yet the ice thickness will determine how the glacier evolves. To avoid these circularity issues, we calibrate the model assuming the glacier area is constant.\n",
    "* **Frontal ablation for marine-terminating glaciers**: currently the frontal ablation parameterization is only set up for marine-terminating glaciers based on the terminus type specific by the RGI. Theoretically, the same framework could be applied to lake-terminating glaciers, but to our knowledge, datasets for calibration are not yet available and the formation of lakes is not yet included in the model.\n",
    "* **PyMC2**: the Markov Chain Monte Carlo (MCMC) methods are currently implemented using PyMC2. The developers of PyMC2 have created a new version PyMC3; however, the new version requires non-trivial changes to PyGEM’s mass balance code and therefore we continue to use PyMC2 at present. Building a conda environment that satisfies all the dependencies including PyMC2 can be challenging, and likely will become increasingly challenging in the future. We hope to develop a new calibration framework in 2023/2024 that is easier to install.\n",
    "* **Continual development**: PyGEM is constantly evolving. We will do our best to keep documents updated, but it's always helpful to let us know if you're using PyGEM so we can ensure you are aware of the latest and/or upcoming changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(publications_target)=\n",
    "# Select Publications\n",
    "* Rounce, D.R., Hock, R., Maussion, F., Hugonnet, R., Kochtitzky, W., Huss, M., Berthier, E., Brinkerhoff, D., Compagno, L., Copland, L., Farinotti, D., Menounos, B., and McNabb, R.W. (2023). “[Global glacier change in the 21st century: Every increase in temperature matters](https://www.science.org/doi/10.1126/science.abo1324)”, Science, 379(6627), pp. 78-83, doi:10.1126/science.abo1324\n",
    "* Rounce, D.R., Hock, R., and Shean, D.E. (2020). “[Glacier mass change in High Mountain Asia through 2100 using the open-source Python Glacier Evolution Model (PyGEM)](https://www.frontiersin.org/articles/10.3389/feart.2019.00331/full)”, Frontiers in Earth Science, 7(331), pp. 1-20, doi:10.3389/feart.2019.00331\n",
    "* Rounce, D.R., Khurana, T., Short, M.B., Hock, R., Shean, D.E., and Brinkherhoff, D.J. (2020). “[Quantifying parameter uncertainty in a large-scale glacier evolution model using Bayesian inference – Application to High Mountain Asia](https://www.cambridge.org/core/journals/journal-of-glaciology/article/quantifying-parameter-uncertainty-in-a-largescale-glacier-evolution-model-using-bayesian-inference-application-to-high-mountain-asia/61D8956E9A6C27CC1A5AEBFCDADC0432)”, Journal of Glaciology, 66(256), pp. 175-187, doi:10.1017/jog.2019.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQS\n",
    "- Add them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Hints\n",
    "- Using argument parser\n",
    "- How to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(install_pygem_target)=\n",
    "# Installing PyGEM\n",
    "The model is stored in two repositories [(see model structure)](model_structure_and_workflow_target) that are installed via PyPI and github as described below.\n",
    "\n",
    "## Setup Conda Environment\n",
    "A conda environment is a directory that contains a specific collection of installed packages. The use of environments reduces issues caused by package dependencies. The model is designed to be compatible with OGGM. We therefore get started by following the [installation instructions from OGGM](https://docs.oggm.org/en/stable/installing-oggm.html).\n",
    "\n",
    "Once your conda environment is setup for OGGM, add the core of PyGEM using pip.\n",
    "\n",
    "```\n",
    "pip install pygem\n",
    "```\n",
    "\n",
    "This will provide you with a conda environment that has the basic functionality to run simple calibration options (e.g., 'HH2015', 'HH2015mod') and simulations. If you want to use the emulators and Bayesian inference, the advanced environment is required.\n",
    "\n",
    "### Developing PyGEM\n",
    "Are you interested in developing PyGEM? If so, we recommend uninstalling pygem, forking the [PyGEM's github repository](https://github.com/drounce/PyGEM) and then [cloning the github repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) onto your local machine.\n",
    "\n",
    "```\n",
    "pip uninstall pygem\n",
    "git clone https://github.com/drounce/PyGEM.git\n",
    "```\n",
    "```{warning}\n",
    "The directory structure here is important. The cloned <em>PyGEM</em> directory should be on the same level as the <em>PyGEM-scripts</em>.\n",
    "```\n",
    "\n",
    "### Advanced environment: GPyTorch (emulator only)\n",
    "If you want to use the emulators additional packages are required. The simplest way to construct this environment is to add <em>- gpytorch</em> to the oggm_env.yml. Then create the environment using:\n",
    "```\n",
    "conda env create -f oggm_env_wemulator.yml\n",
    "```\n",
    "\n",
    "The only way to find out if your package dependencies work is to test it by running the model. Make sure to install PyGEM-Scripts and then [test the model](test_model_target).\n",
    "\n",
    "**If your environment is not set up properly, errors will arise related to missing modules. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.** As of July 2023, adding GPyTorch to OGGM's existing environment was quite simple using the .yml file provided by [OGGM](https://docs.oggm.org/en/stable/installing-oggm.html).\n",
    "\n",
    "\n",
    "### Advanced environment: PyMC2 and GPyTorch\n",
    "If you want to use the emulators or Bayesian inference associated with PyGEM additional packages are required.\n",
    "\n",
    "```{warning}\n",
    "The current dependencies are fairly tricky as PyMC2 is now fairly old and no longer supported. We anticipate developing code that relies on more user-friendly packages in the future, but for the time being have patience and do your best to work through the environment issues.\n",
    "```\n",
    "PyMC2 requires Python3.8. Therefore, you may want to re-install your original environment and explicitly specify Python 3.8. Once your environment is setup, activate your environment.\n",
    "\n",
    "Next, install the modules required for the emulator.\n",
    "```\n",
    "pip install torch\n",
    "pip install gpytorch\n",
    "```\n",
    "\n",
    "Next, install the modules required for Bayesian inference.\n",
    "```\n",
    "pip install pymc\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "You may try to replace pip install with conda install as conda may help solve dependencies. However, creating this environment can take a long time (> 1 hr), so be patient.\n",
    "```\n",
    "\n",
    "The only way to find out if your package dependencies work is to test it by running the model. Make sure to install PyGEM-Scripts and then [test the model](test_model_target).\n",
    "\n",
    "**If your environment is not set up properly, errors will arise related to missing modules. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.** Getting a correct package installed took the lead developer over a day and unfortunately other users have commented that the directions used by the lead developer have not worked for others due to newer computers or different operating systems.\n",
    "\n",
    "\n",
    "## Install PyGEM-Scripts\n",
    "The scripts that are used to run PyGEM are located in the [PyGEM-Scripts repository](https://github.com/drounce/PyGEM-scripts) on github. To run the model, you can either (i) clone the repository or (ii) fork the repository to develop/add your own scripts. For instructions, follow github’s instructions on [cloning](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository) or [forking a repository](https://docs.github.com/en/get-started/quickstart/fork-a-repo). Once the repository is installed on your local machine, you can run the model from this directory.\n",
    "\n",
    "```{note}\n",
    "Be sure that your [directory structure](directory_structure_target) is setup properly before you try running the model!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_model_target)=\n",
    "# Test Model\n",
    "Once the conda environment is [properly installed](install_pygem_target) and you have an understanding of the model components, you are ready to run the model. As described in the [model workflow](model_workflow_target), the model is meant to be run as a sequence of commands from the command line. To test if the model is properly installed and become familiar with the data, sample data for a test run are provided for Khumbu Glacier (RGI60-15.03733) [(download sample data)](https://drive.google.com/file/d/159zS-oGWLHG9nzkFdsf6Uh4-w9lJSt8H/view?usp=sharing). Below are two test workflows for the simple and advanced calibration schemes, and one additional calibrating and running simulations for marine-terminating (\"tidewater\") glaciers. Sample data for a test run are provided for Khumbu Glacier (RGI60-15.03733) [(download tidewater sample data)](https://drive.google.com/file/d/1Y9mVw9whEq7b4LURbOCxq-qopSwxoTnZ/view?usp=sharing).\n",
    "\n",
    "```{toctree}\n",
    "---\n",
    "caption: Test Case:\n",
    "maxdepth: 2\n",
    "---\n",
    "\n",
    "test_pygem_simple\n",
    "test_pygem_advanced\n",
    "test_pygem_tidewater\n",
    "```\n",
    "\n",
    "```{warning}\n",
    "If your environment is not set up properly, errors will arise related to missing modules. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_simple_target)=\n",
    "# Simple Test\n",
    "## Simple calibration\n",
    "Open **pygem_input.py** and check the following (changing as needed):\n",
    "* glac_no = ['15.03733']\n",
    "* ref_startyear = 2000\n",
    "* ref_endyear = 2019\n",
    "* option_calibration = 'HH2015'\n",
    "* option_dynamics = None\n",
    "\n",
    "Then proceed with running the calibration as follows:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "```{note}\n",
    "Command line considerations:\n",
    "<br>Look at arguments in getparser() function for additional command line options, which include options for running in parallel (i.e., we set option_parallels=0 to turn this option off), debugging, etc.\n",
    "```\n",
    "If successful, the script will run without errors and the following will be generated:\n",
    "* ../Output/calibration/15/15.03733-modelprms_dict.pkl\n",
    "\n",
    "This is a .pkl file that contains the calibration data.\n",
    "\n",
    "## Simple present-day simulation\n",
    "You are now ready to run a simulation. Go back to **pygem_input.py** and check/change:\n",
    "* option_dynamics = 'OGGM'\n",
    "* use_reg_glena = False\n",
    "\n",
    "Then proceed with running the simulation for a reference time period as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0\n",
    "```\n",
    "If successful, the script will run without errors and the following will be generated:\n",
    "* ../Output/simulation/15/ERA5/stats/15.03733_ERA5_HH2015_ba1_1sets_2000_2020_all.nc\n",
    "\n",
    "This is a netcdf file that stores model output from the simulation.\n",
    "\n",
    "## Simple future simulation\n",
    "Now you can try simulating the glacier into the future. Got back to **pygem_input.py** and check/change:\n",
    "* gcm_startyear = 2000\n",
    "* gcm_endyear = 2100\n",
    "\n",
    "Then proceed with running the simulation, while specifying the GCM and scenario through the command line as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0 -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "\n",
    "If successful, the script will run without errors and the following with be generated: \n",
    "* ../Output/simulation/15/CESM2/ssp245/stats/15.03733_CESM2_ssp245_HH2015_ba1_1sets_2000_2020_all.nc\n",
    "\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run PyGEM for your study region!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_advanced_target)=\n",
    "# Advanced Test\n",
    "Here we will go over testing both the emulator and Bayesian inference.\n",
    "\n",
    "## MCMC Calibration\n",
    "Open **pygem_input.py** and check the following (changing as needed):\n",
    "* glac_no = ['15.03733']\n",
    "* ref_startyear = 2000\n",
    "* ref_endyear = 2019\n",
    "* option_calibration = 'emulator'\n",
    "* option_dynamics = None\n",
    "\n",
    "Then proceed with running the calibration:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "```{note}\n",
    "Command line considerations:\n",
    "<br>Look at arguments in getparser() function for additional command line options, which include options for running in parallel (i.e., we set option_parallels=0 to turn this option off), debugging, etc.\n",
    "```\n",
    "If successful, the script will run without errors and the following datasets will be generated:\n",
    "* ../Output/calibration/15/15.03733-modelprms_dict.pkl\n",
    "* ../emulator/sims/15/15.03733-100_emulator_sims.csv\n",
    "* ../emulator/models/15/15.03733-emulator-mb_mwea.pth\n",
    "* ../emulator/models/15/15.03733-emulator-mb_mwea_extra.pkl\n",
    "\n",
    "These contain the calibration data, simulations used to create the emulator, and information needed to recreate the emulator.\n",
    "\n",
    "```{note}\n",
    "Normally the next step would be to run this for all glaciers in a region and then determine the prior distributions for the MCMC methods; however, given we're just testing on a single glacier, skip this step and use the default priors from the '../Output/calibration/priors.region.csv'.\n",
    "```\n",
    "\n",
    "Next, run the calibration again using the Bayesian inference. Open the **pygem_input.py** and check/change the following:\n",
    "* option_calibration = 'MCMC'\n",
    "\n",
    "Then proceed with running the calibration:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "If successful, the script will run without errors and no new calibration file will be produced. Why? Because the modelprms_dict.pkl file contains all the data. To quickly check that the MCMC was successful, the model will generate the following:\n",
    "* ../Output/mcmc_success/15/15.03733-mcmc_success.txt\n",
    "\n",
    "```{warning}\n",
    "This (i.e., the run_calibration.py with the emulator and MCMC options) is where errors related to missing modules will arise. We recommend that you work through adding the missing modules and use StackOverflow to identify any additional debugging issues related to potential missing modules or module dependencies.\n",
    "```\n",
    "\n",
    "## MCMC simulations\n",
    "You are now ready to run a simulation. We'll skip the simulation for the reference period and go directly to running a future simulation. Go back to **pygem_input.py** and check/change:\n",
    "* gcm_startyear = 2000\n",
    "* gcm_endyear = 2100\n",
    "* option_dynamics = 'OGGM'\n",
    "* use_reg_glena = False\n",
    "* sim_iters = 50\n",
    "\n",
    "Then proceed with running the simulation, while specifying the GCM and scenario through the command line as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0 -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "If successful, the script will run without errors and the following with be generated: \n",
    "* ../Output/simulation/15/CESM2/ssp245/stats/15.03733_CESM2_ssp245_MCMC_ba1_1sets_2000_2020_all.nc\n",
    "\n",
    "This is a netcdf file that stores model output from the simulation.\n",
    "\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run PyGEM for your study region!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(test_tidewater_target)=\n",
    "# Advanced Test - Tidewater Glaciers\n",
    "Here we will go over testing the calibration of the frontal ablation parameterization. <br><br>Note that in a typical regional modeling workflow, the ice viscocity (\"Glen A\") model parameter would already be calibrated for the land-terminating glaciers uch that the modeled ice volume roughly matches the ice volume estimates [(see run_calibration_icethickness)](run_calibration_icethickness_overview_target). Here, we have already provided you with output files, which include this calibration.\n",
    "```{warning}\n",
    "The frontal ablation calibration relies on a mass balance emulator; therefore, you will need to install GPyTorch [(see Installing PyGEM)](install_pygem_target).\n",
    "```\n",
    "\n",
    "## Frontal Ablation Calibration\n",
    "Open **pygem_input.py** and check the following (changing as needed):\n",
    "* glac_no = ['1.03622']\n",
    "* ref_startyear = 2000\n",
    "* ref_endyear = 2019\n",
    "* include_calving = False\n",
    "* option_calibration = 'emulator'\n",
    "* hugonnet_fn = 'df_pergla_global_20yr-filled.csv'\n",
    "* calving_fp = main_directory + '/../calving_data/'\n",
    "* calving_fn = 'frontalablation_data_test.csv'\n",
    "* option_dynamics = 'OGGM'\n",
    "* include_debris = False\n",
    "\n",
    "```{note}\n",
    "It may feel counterintuitive to set <em>include_calving = False</em>; however, this is needed in the initial steps to avoid circularity issues.\n",
    "```\n",
    "Then proceed with running an initial calibration to create the emulator:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "```{note}\n",
    "Command line considerations:\n",
    "<br>Look at arguments in getparser() function for additional command line options, which include options for running in parallel (i.e., we set option_parallels=0 to turn this option off), debugging, etc.\n",
    "```\n",
    "If successful, the script will run without errors and the following datasets will be generated:\n",
    "* ../Output/calibration/01/1.03622-modelprms_dict.pkl\n",
    "* ../emulator/sims/01/1.03622-100_emulator_sims.csv\n",
    "* ../emulator/models/01/1.03622-emulator-mb_mwea.pth\n",
    "* ../emulator/models/01/1.03622-emulator-mb_mwea_extra.pkl\n",
    "* ../oggm_gdirs/per_glacier/RGI60-01/RGI60-01.03/RGI60-01.03622/*\n",
    "\n",
    "These contain the calibration data, simulations used to create the emulator, and information needed to recreate the emulator. The glacier directory (oggm_gdirs) with relevant glacier information is created automatically as well.\n",
    "\n",
    "<br><br>Next, run the frontal ablation calibration. Open the **pygem_input.py** and check/change the following:\n",
    "* include_calving = True\n",
    "\n",
    "Then open **run_calibration_frontalablation.py** and check/change the following:\n",
    "* regions = [1]\n",
    "* option_ind_calving_k = True\n",
    "* calving_fp = pygem_prms.main_directory + '/../calving_data/'\n",
    "* calving_fn = 'frontalablation_data_test.csv'\n",
    "\n",
    "```{warning}\n",
    "This script is currently hard-coded. We hope to change this to be automated from pygem_input.py and the command line in the future. For now, please be patient and open and modify these scripts as instructed.\n",
    "```\n",
    "If successful, the script will run without errors and the following datasets will be generated:\n",
    "* ../calving_data/analysis/1-calving_cal_ind.csv\n",
    "\n",
    "Then open **run_calibration_frontalablation.py** and check/change the following:\n",
    "* option_ind_calving_k = False\n",
    "* option_merge_calving_k = True\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "If successful, the script will run without errors and the following dataset will be generated: \n",
    "* ../calving_data/analysis/all-calving_cal_ind.csv\n",
    "\n",
    "This data simply merges all the different regions together, which is essentially pointless for a single glacier test, but useful to get into good workflow habits.\n",
    "\n",
    "<br><br> Next, update the climatic-basal mass balance data by removing the frontal ablation from the total mass change. Open **run_calibration_frontalablation.py** and check/change the following:\n",
    "* option_merge_calving_k = False\n",
    "* option_update_mb_data = True\n",
    "\n",
    "If successful, the script will run without errors and the following dataset will be generated:\n",
    "* ../DEMs/Hugonnet2020/df_pergla_global_20yr-filled-facorrected.csv\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run simulations with frontal ablation included. However, now that frontal ablation is included, it's important to update the calibration data and use the latest datasets produced.\n",
    "\n",
    "## Update datasets and recalibrate model parameters\n",
    "Update the datasets in **pygem_input.py** and check/change:\n",
    "* hugonnet_fn = 'df_pergla_global_20yr-filled-FAcorrected.csv'\n",
    "* calving_fp = main_directory + '/../calving_data/analysis/'\n",
    "* calving_fn = 'all-calving_cal_ind.csv'\n",
    "\n",
    "Then recalibrate the model parameters by running:\n",
    "```\n",
    "python run_calibration.py -option_parallels=0\n",
    "```\n",
    "\n",
    "If successful, the script will run without errors and no new datasets will be generated. Why? It's because the model parameters dictionary already exists, so it will simply update the parameters within there.\n",
    "\n",
    "\n",
    "## Run simulation\n",
    "Then proceed with running the simulation, while specifying the GCM and scenario through the command line as follows:\n",
    "```\n",
    "python run_simulation.py -option_parallels=0 -gcm_name='CESM2' -scenario='ssp245'\n",
    "```\n",
    "If successful, the script will run without errors and the following with be generated: \n",
    "* ../Output/simulation/01/CESM2/ssp245/stats/1.03622_CESM2_ssp245_emulator_ba1_1sets_2000_2100_all.nc.nc\n",
    "\n",
    "This is a netcdf file that stores model output from the simulation.\n",
    "\n",
    "CONGRATULATIONS! You are now ready to run PyGEM for your study region and consider frontal ablation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(model_output_overview_target)=\n",
    "# Model Output \n",
    "The model outputs a variety of data including monthly mass balance and its components (accumulation, melt, refreezing, frontal ablation, glacier runoff), and annual mass, mass below sea level, and area. Results are written as a netcdf file (.nc) for each glacier. If multiple simulations are performed (e.g., for Monte Carlo simulations), then statistics related to the median and median absolute deviation are output for each parameter. In addition to this standard glacier-wide output, binned output is also available, which include the bin\\’s surface elevation, volume, thickness, and climatic mass balance annually. Additional output can be exported by modifying the **run_simulation.py** script.\n",
    "\n",
    "## Post-processing Data\n",
    "- Add examples of merge and files produced\n",
    "\n",
    "## Analyzing Results\n",
    "Various Jupyter Notebooks are available to view results. Some analyses require additional datasets (e.g., specifying watersheds), which will be described in the files.\n",
    "- **analyze_glacier_change_byRGIRegion.ipynb** <br>This notebook can be used to plot glacier mass, area, and runoff changes for a given region as shown in the figure below:\n",
    "```{figure} _static/analyze_glacier_change_region11.png\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "```\n",
    "- **analyze_glacier_change_byWatershed.ipynb** <br>This notebook can be used to aggregate glacier mass, area, and runoff into watersheds; specifically, it will create new netcdf files per watershed such that after the initial aggregation, analyses can be performed much more rapidly. The notebook continues to show an example plot of glacier mass, area, and runoff changes for each watershed in an example region:\n",
    "```{figure} _static/analyze_glacier_change_watershed11.png\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "```\n",
    "```{note}\n",
    "This notebook assumes that you have a \"dictionary\", i.e., a .csv file, that has each glacier of interest and the watershed (or other grouping) name associated with each glacier.\n",
    "```\n",
    "- **analyze_glacier_change_CrossSection.ipynb** <br>This notebook can be used to plot cross sections of an individual glacier's ice thickness over time for an ensemble of GCMs:\n",
    "```{figure} _static/15.03733_profile_2100_ssps.png\n",
    "---\n",
    "width: 100%\n",
    "---\n",
    "```\n",
    "```{note}\n",
    "Want to create a gif of cross sections evolving over time instead? Check out **analyze_glacier_change_CrossSection-gif.ipynb**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(scripts_overview_target)=\n",
    "# Script Details\n",
    "The [Model Workflow](model_workflow_target) and [Test Model](test_model_target) sections provide a general overview of the workflows and how to use the scripts. Here we provide more detail of the primary scripts used to run PyGEM (from the [PyGEM-Scripts](https://github.com/drounce/PyGEM-scripts/tree/main) repository). This information can help support your understanding of the inner workings of the code and also provide an overview for developers who may want to fork the codes and create new content. The following scripts are described:\n",
    "\n",
    "```{toctree}\n",
    "---\n",
    "caption: Primary Scripts:\n",
    "maxdepth: 1\n",
    "---\n",
    "\n",
    "pygem_input_overview\n",
    "run_calibration_frontalablation_overview\n",
    "run_calibration_overview\n",
    "run_calibration_icethickness_overview\n",
    "run_simulation_overview\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pygem_input_overview_target)=\n",
    "# pygem_input.py\n",
    "This script is where the user is able to specify the glaciers to model, choose model parameterizations and calibration options, specify relative filepaths and filenames for the model to function, and specify other model details and constants. The script is loosely organized to have the most frequently changed items at the top of the file, while also separating the file into organized chunks. The general organization is:\n",
    "\n",
    "* [Model setup directory](input_model_setup_target)\n",
    "* [Glacier selection](input_glacier_selection_target)\n",
    "* [Climate data and time periods](input_climate_data_time_target)\n",
    "* [Calibration options](input_cal_options_target)\n",
    "* [Simulation and glacier dynamics options](input_sim_dyn_options_target)\n",
    "* [Model parameters](input_model_prms_target)\n",
    "* [Mass balance model options](input_mb_model_options_target)\n",
    "* [Climate data filepaths and filenames](input_climate_data_files_target)\n",
    "* [Glacier data](input_glacier_data_target)\n",
    "* [Model time period details](input_model_time_details_target)\n",
    "* [Model constants](input_model_constants_target)\n",
    "* [Debugging options](input_debugging_options)\n",
    "\n",
    "```{note}\n",
    "**pygem_input.py** is heavily commented, so this information should hopefully be clear when modifying variables within the file itself.\n",
    "```\n",
    "(input_model_setup_target)=\n",
    "## Model Setup Directory\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| main_directory | os.getcwd() | main directory used for relative filepaths |\n",
    "| output_filepath | str | output filepath |\n",
    "| model_run_date | str | date associated with model runs <br>(useful for knowing version of model used) |\n",
    "\n",
    "(input_glacier_selection_target)=\n",
    "## Glacier Selection\n",
    "Several options exist to specify the glaciers, but they generally fall into specifying based on the RGI regions or glacier numbers. Additional options exist to include/exclude certain types of glaciers for detailed studies.\n",
    "\n",
    "**Specify glaciers**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| rgi_regionsO1 | list of int | 1st order region number |\n",
    "| rgi_regionsO2 | list of int or 'all' | 2nd order region number ('all' means to include all subregions) |\n",
    "| rgi_glac_number | list of str or 'all' | glacier number (e.g., '00001') ('all' means to include all glaciers in a given region/subregion) |\n",
    "| glac_no_skip | list of str or None | glacier numbers (e.g., '1.00001') of any glaciers to exclude |\n",
    "| glac_no | list or None | glacier numbers (e.g., '1.00001') of glaciers to run |\n",
    "\n",
    "```{warning}\n",
    "Set glac_no will always overwrite the rgi regions, so if you want to use the rgi region options, then set glac_no=None\n",
    "```\n",
    "\n",
    "**Specify types of glaciers**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| include_landterm | [True, False] | switch to include land-terminating glaciers |\n",
    "| include_laketerm | [True, False] | switch to include lake-terminating glaciers |\n",
    "| include_tidewater | [True, False] | switch to include marine-terminating glaciers |\n",
    "| ignore_calving | [True, False] | switch to ignore calving and treat marine-terminating glaciers as land-terminating |\n",
    "  \n",
    "**OGGM Glacier Directory Filepath**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| oggm_base_url | str | filepath to OGGM's server with glacier directories |\n",
    "| logging_level | str | logging level for OGGM. Options: DEBUG, INFO, WARNING, ERROR, WORKFLOW, CRITICAL (recommended WORKFLOW) |\n",
    "\n",
    "\n",
    "(input_climate_data_time_target)=\n",
    "## Climate Data and Time Periods\n",
    "**Reference climate data**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| ref_gcm_name | ['ERA5'] | reference climate dataset |\n",
    "| ref_startyear | int | first year of model run (reference dataset) |\n",
    "| ref_endyear | int | last year of model run (reference dataset) |\n",
    "| ref_wateryear | ['calendar', 'hydro', 'custom'] | defining the calendar being used. If using custom, additional details required (see [Model Time Period Details](input_model_time_details_target)) |\n",
    "| ref_spinupyears | int | number of spin up years (suggest 0) |\n",
    "\n",
    "**Future climate data**\n",
    "<br>Note that this is separate to account for bias corrections between reference and future climate data.\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| gcm_startyear | int | first year of model run |\n",
    "| gcm_endyear | int | last year of model run |\n",
    "| gcm_wateryear | ['calendar', 'hydro', 'custom'] | defining the calendar being used. If using custom, additional details required (see [Model Time Period Details](input_model_time_details_target) |\n",
    "| gcm_spinupyears | int | number of spin up years (suggest 0) |\n",
    "| constantarea_years | int | number of years to not let the area or volume change (suggest 0) |\n",
    "\n",
    "**Hindcast options**\n",
    "<br>These options will flip the climate data array so 1960-2000 would run 2000-1960 ensuring that glacier area at 2000 is correct; however, due to nonlinearities a run starting at 1960 would not provide the same mass change and area at 2000.\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| hindcast | [True, False] | switch to run hindcast simulation |\n",
    "\n",
    "\n",
    "(input_cal_options_target)=\n",
    "## Calibration Options\n",
    "<br>These variables specify the calibration option as well as important details concerning the options or output files.\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_calibration | ['emulator', 'MCMC', 'MCMC_fullsim' 'HH2015', 'HH2015mod'] | calibration option |\n",
    "| priors_reg_fullfn | str | filepath to where the prior distributions for the MCMC are stored. Note this is used in the run_calibration.py for MCMC as well as for the run_calibration_frontalablation.py in case preference is to use regional parameters instead of individual parameters. |\n",
    "\n",
    "**HH2015-specific options**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| tbias_init | float |  initial temperature bias |\n",
    "| tbias_step | float | step for coarse optimization search |\n",
    "| kp_init | float | initial precipitation factor |\n",
    "| kp_bndlow | float | lower bound for precipitation factor |\n",
    "| kp_bndhigh | float | upper bound for precipitation factor |\n",
    "| ddfsnow_init | float | initial degree-day factor of snow |\n",
    "| ddfsnow_bndlow | float | lower bound for degree-day factor of snow |\n",
    "| ddfsnow_bndhigh | float | upper bound for degree-day factor of snow |\n",
    "  \n",
    "```{warning}\n",
    "Huss and Hock (2015) uses a ratio of the degree-day factor of ice to snow of 2. If you want to use this same calibration framework, then you need to set ddfsnow_iceratio=0.5 in [model parameters below](input_model_prms_target)\n",
    "```\n",
    "    \n",
    "**HH2015mod-specific options**\n",
    "<br>Some variables have been described above. Only variables shown below:\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| method_opt | ['SLSQP', 'L-BFGS-B'] | SciPy optimization scheme |\n",
    "| params2opt | ['tbias', 'kp'] | parameters to optimize |\n",
    "| ftol_opt | float | tolerance for SciPy optimization scheme |\n",
    "| eps_opt | float | epsilon (adjust variables for jacobian) for SciPy optimization scheme (0.01 works) |\n",
    "    \n",
    "**emulator-specific options**\n",
    "<br>Some variables have been described above. Only variables shown below: \n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| emulator_sims | int |  Number of simulations to develop the emulator |\n",
    "| overwrite_em_sims | [True, False] | switch to overwrite emulator simulations |\n",
    "| opt_hh2015_mod | [True, False] | switch to also perform the HH2015_mod calibration using the emulator |\n",
    "| emulator_fp | str | filepath to store emulator details |\n",
    "| option_areaconstant | [True, False] | switch to keep area constant or evolve |\n",
    "\n",
    "Prior distributions:\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| tbias_disttype | ['truncnormal', 'uniform'] | temperature bias prior distribution |\n",
    "| tbias_sigma | float | temperature bias standard deviation for truncnormal distribution |\n",
    "| kp_gamma_alpha | float | precipitation factor gamma distribution alpha |\n",
    "| kp_gamma_beta | float | precipitation factor gamma distribution beta |\n",
    "| ddfsnow_disttype | ['truncnormal']  | degree-day factor of snow distribution |\n",
    "| ddfsnow_mu | float | degree-day factor of snow mean |\n",
    "| ddfsnow_sigma | float | degree-day factor of snow standard deviation |\n",
    "| ddfsnow_bndlow | float | degree-day factor of snow lower bound |\n",
    "| ddfsnow_bndhigh | float | degree-day factor of snow upper bound |\n",
    "\n",
    "**MCMC and MCMC_fullsim - specific options**\n",
    "<br>Some variables have been described above. Only variables shown below:\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| tbias_stepsmall | float | temperature bias small stepsize to avoid infeasible starting set of parameters for Markov Chain |\n",
    "| n_chains | int | number of chains (min 1, max 3) |\n",
    "| mcmc_sample_no | int | number of steps (10000 was found to be sufficient in HMA) |\n",
    "| mcmc_burn_no | int | number of steps to burn-in (0 records all steps in chain) |\n",
    "| mcmc_step | [None, 'am'] | Markov Chain step option (None uses default, while am refers to adaptive metropolis algorithm) |\n",
    "| thin_interval | int | thin interval if need to reduce file size (best to leave at 1 if space allows) |\n",
    "| ddfsnow_start | ddfsnow_mu | degree-day factor of snow initial chain value |\n",
    "| kp_disttype | ['gamma', 'lognormal', 'uniform'] | precipitation factor distribution type |\n",
    "| kp_start | float | precipitation factor initial chain value |\n",
    "| tbias_disttype | ['normal', 'truncnormal', 'uniform'] | temperature bias distribution type |\n",
    "| tbias_start | float | temperature bias initial chain value |\n",
    "\n",
    "**Calibration Dataset**\n",
    "<br>This section will be updated as additional datasets are incorporated. For now, the following are used:\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| hugonnet_fp | str | filepath to pre-processed Hugonnet et al. (2021) data |\n",
    "| hugonnet_fn | str | filename of pre-processed Hugonnet et al. (2021) data |\n",
    "| hugonnet_mb_cn | str | mass balance column name |\n",
    "| hugonnet_mb_err_cn | str | mass balance uncertainty column name |\n",
    "| hugonnet_rgi_glacno_cn | str | RGIId or glacier number column name |\n",
    "| hugonnet_mb_clim_cn | str | climatic mass balance column name |\n",
    "| hugonnet_mb_clim_err_cn | str | climatic mass balance uncertainty column name |\n",
    "| hugonnet_time1_cn | str | observation start time column name |\n",
    "| hugonnet_time2_cn | str | observation end time column name |\n",
    "| hugonnet_area_cn | str | glacier area column name |\n",
    "  \n",
    "**Calibration Frontal Ablation Parameter**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| calving_fp | str | filepath to pre-processed frontal ablation parameters |\n",
    "| calving_fn | str | filename of pre-processed frontal ablation parameters |\n",
    "| icethickness_cal_frac_byarea | float | regional glacier area fraction that is used to calibrate the ice thickness (e.g., 0.9 means only the largest 90% of glaciers by area will be used to calibrate glen's a for that region) |\n",
    "\n",
    "\n",
    "(input_sim_dyn_options_target)=\n",
    "# Simulation and Glacier Dynamics Options\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_dynamics | ['OGGM', 'MassRedistributionCurves', None] | glacier dynamics scheme option |\n",
    "    \n",
    "**MCMC-specific**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| sim_iters | int | number of simulations |\n",
    "| sim_burn | int | number of burn-in (if burn-in is done in MCMC sampling, then don't do here) |\n",
    "\n",
    "**General Parameters**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| output_sim_fp | str | output filepath to store simulations |\n",
    "| sim_stat_cns | ['mean', 'std', '2.5%', '25%', 'median', '75%', '97.5%'] | names of statistics to record for simulations with multiple parameter sets |\n",
    "| export_essential_data | [True, False] | switch to export essential data (ex. mass balance components, ElA, etc.) |\n",
    "| export_binned_thickness | [True, False] | switch to export binned datasets |\n",
    "| export_binned_area_threshold | float | area threshold for exporting binned thicknesses |\n",
    "| export_extra_vars | [True, False] | switch to export extra variables (temp, prec, melt, acc, etc.) |\n",
    "\n",
    "**Bias Correction**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_bias_adjustment | [0, 1, 2] | bias correction option (0: no adjustment, 1: new prec scheme and temp building on HH2015, 2: HH2015 methods) |\n",
    "\n",
    "**OGGM Glacier Dynamics Parameters**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| cfl_number | float | time step threshold (seconds) |\n",
    "| cfl_number_calving | float | time step threshold (seconds) for marine-terimating glaciers |\n",
    "| glena_reg_fullfn | str | full filepath and name of Glen's parameter A values |\n",
    "| use_reg_glena | [True, False] | switch to use regionally calibrated Glen's parameter A |\n",
    "| fs | float | sliding parameter |\n",
    "| glen_a_multiplier | float | Glen's parameter A multiplier |\n",
    "\n",
    "**Mass Redistribution Curve Parameters**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| icethickness_advancethreshold | float | advancing glacier ice thickness change threshold (m) |\n",
    "| terminus_percentage | float | precentage of glacier area considered to be terminus (used to size advancing new bins) |\n",
    "\n",
    "\n",
    "(input_model_prms_target)=\n",
    "## Model Parameters\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| use_calibrated_modelparams | [True, False] | switch to use calibrated model parameters |\n",
    "| use_constant_lapserate | [True, False] | switch to use constant value specified below or not |\n",
    "| kp | float | precipitation factor (-) |\n",
    "| tbias | float | temperature bias (deg C) |\n",
    "| ddfsnow | float | degree-day factor of snow (m w.e. d$^{-1}$ degC$^{-1}$) |\n",
    "| ddfsnow_iceratio | float | ratio degree-day factor snow snow to ice |\n",
    "| ddfice | ddfsnow / ddfsnow_iceratio | degree-day factor of ice (m w.e. d$^{-1}$ degC$^{-1}$) |\n",
    "| precgrad | float | precipitation gradient on glacier (m$^{-1}$) |\n",
    "| lapserate | float | temperature lapse rate for both gcm to glacier and on glacier between elevation bins (K m$^{-1}$) |\n",
    "| tsnow_threshold | float | temperature threshold for snow (deg C) |\n",
    "| calving_k | float | frontal ablation rate (yr$^{-1}$) |\n",
    "\n",
    "\n",
    "(input_mb_model_options_target)=\n",
    "## Mass Balance Model Options\n",
    "**Surface Type Options**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_surfacetype_initial | 1 | initial surface type option (1: median elevation distinguishes firn/ice, 2: mean elevation) |\n",
    "| include_firn | [True, False] | switch to include firn or treat it as snow |\n",
    "| include_debris | [True, False] | switch to account for debris with sub-debris melt factors or not |\n",
    "  \n",
    "  \n",
    "**Downscaling Options**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_elev_ref_downscale | ['Zmed', 'Zmax', 'Zmin'] | reference elevation for downscaling climate variables to glacier |\n",
    "| option_temp2bins | [1] | downscale temperature to bins options (1: use lr_gcm and lr_glac to adjust temp from gcm to the glacier bins) |\n",
    "| option_adjusttemp_surfelev | [0, 1] | switch to adjust temperatures based on surface elevation changes or not |\n",
    "| option_prec2bins | [1] | downscale precipitation to bins (currently only based on precipitation factor and precipitation gradient) |\n",
    "| option_preclimit | [0, 1] | switch to limit the uppermost 25% using an expontial function |\n",
    "\n",
    "**Accumulation Options**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_accumulation | [1, 2] | accumulation threshold option: (1) single threshold or (2) +/- 1 degree linear interpolation |\n",
    "\n",
    "**Ablation Options**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_ablation | [1, 2] | compute ablation using (1) monthly temperature or (2) superimposed daily temperatures |\n",
    "| option_ddf_firn | [0, 1] | estimate degree-day factor of firn by (0) degree-day factor of snow or (2) mean of degree-day factor of snow and ice |\n",
    "\n",
    "**Refreezing Options** (options: 'Woodward' or 'HH2015')\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_refreezing | ['Woodward', 'HH2015'] | compute refreezing using annual air temperatures ('Woodward') or heat conduction ('HH2015') |\n",
    "\n",
    "Woodward-specific options:\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| rf_month | int | month to reset refreeze |\n",
    "\n",
    "HH2015-specific options:\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| rf_layers | int | number of layers for refreezing model (8 is sufficient according to Matthias Huss and some tests) |\n",
    "| rf_dz | float | layer thickness (m) |\n",
    "| rf_dsc | int | number of time steps for numerical stability (3 is sufficient - Matthias) |\n",
    "| rf_meltcrit | float | critical amount of melt (m w.e.) for initializing refreezing module |\n",
    "| pp | float | additional refreeze water to account for water refreezing at bare-ice surface |\n",
    "| rf_dens_top | float | snow density at surface (kg m$^{-3}$) |\n",
    "| rf_dens_bot | float | snow density at bottom refreezing layer (kg m$^{-3}$) |\n",
    "| option_rf_limit_meltsnow | [0, 1] | switch to limit the amount of refreezing to the amount of snow melt |\n",
    "\n",
    "\n",
    "(input_climate_data_files_target)=\n",
    "## Climate Data Filepaths and Filenames\n",
    "Here is where you should add information for any new datasets as well as adding functionality to class_climate.py\n",
    "\n",
    "**ERA5**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| era5_fp | str | ERA5 filepath |\n",
    "| era5_temp_fn |  str | ERA5 temperature filename | \n",
    "| era5_tempstd_fn |  str | ERA5 temperature daily standard deviation filename | \n",
    "| era5_prec_fn | str | ERA5 precipitation filename | \n",
    "|  era5_elev_fn |  str | ERA5 elevation filename | \n",
    "|  era5_pressureleveltemp_fn |  str | ERA5 pressure level temperature filename | \n",
    "|  era5_lr_fn |  str | ERA5 lapse rate filename | \n",
    "\n",
    "**CMIP5 (GCM Data)**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| cmip5_fp_var_prefix | str | filepath prefix for CMIP5 variables (temperature, precipitation) |\n",
    "| cmip5_fp_var_ending | str | filepath ending for CMIP5 variables (temperature, precipitation) |\n",
    "| cmip5_fp_fx_prefix | str | filepath prefix for CMIP5 fixed variables (elevation) |\n",
    "| cmip5_fp_fx_ending | str | filepath ending for CMIP5 fixed variables (elevation |\n",
    "\n",
    "**CMIP6 (GCM Data)**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "|cmip6_fp_prefix | str | filepath prefix for CMIP6 variables |\n",
    "\n",
    "\n",
    "(input_glacier_data_target)=\n",
    "## Glacier Data\n",
    "**Randolph Glacier Inventory**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| rgi_fp | str | filepath to regional attributes files |\n",
    "| rgi_lat_colname | str | RGI latitude column name |\n",
    "| rgi_lon_colname | str | RGI longitude column name' |\n",
    "| elev_colname | str | elevation column name |\n",
    "| indexname | str | index column name |\n",
    "| rgi_O1Id_colname | str | glacier number column name |\n",
    "| rgi_glacno_float_colname | str | glacier number as float column name |\n",
    "| rgi_cols_drop | list of str | column names from table to drop <br>(e.g., ['GLIMSId','BgnDate','EndDate','Status','Linkages','Name'] or []) |\n",
    "\n",
    "**Ice Thickness Data**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| h_consensus_fp | str | filepath to consensus ice thickness estimates |\n",
    "| binsize | int | elevation bin height (m) |\n",
    "| hyps_data | 'OGGM' | hypsometry dataset |\n",
    "| oggm_gdir_fp | str | OGGM glacier directories filepath |\n",
    "| overwrite_gdirs | [True, False] | switch to overwrite glacier directories |\n",
    "\n",
    "**Debris Data**\n",
    "\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| debris_fp | str | filepath to debris data |\n",
    "    \n",
    "    \n",
    "(input_model_time_details_target)=\n",
    "## Model Time Period Details\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| option_leapyear | [0, 1] | option to (1) include leap year days or (0) exclude leap years so February always has 28 days |\n",
    "| startmonthday | str | start month and day for custom calendars (e.g., '06-01') |\n",
    "| endmonthday | str | end month and day for custom calendars (e.g., '05-31') |\n",
    "| wateryear_month_start | int | month starting for hydrological calendar\n",
    "| winter_month_start | int | first month of winter |\n",
    "| summer_month_start | int | first month of summer |\n",
    "| option_dates | [1, 2] | use dates from (1) date table (first of each month) or (2) dates from climate data\n",
    "| timestep | 'monthly' | model timestep |\n",
    "\n",
    "\n",
    "(input_model_constants_target)=\n",
    "## Model Constants\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| density_ice | float | density of ice (kg m$^{-3}$) |\n",
    "| density_water | float | density of water (kg m$^{-3}$) |\n",
    "| area_ocean | float | area of ocean |\n",
    "| k_ice | float | thermal conductivity of ice (J s$^{-1}$ K$^{-1}$ m$^{-1}$) |\n",
    "| k_air | float | thermal conductivity of air (J s$^{-1}$ K$^{-1}$ m$^{-1}$) |\n",
    "| ch_ice | float | volumetric heat capacity of ice (J K$^{-1}$ m$^{-3}$) |\n",
    "| ch_air | float | volumetric Heat capacity of air (J K$^{-1}$ m$^{-3}$) |\n",
    "| Lh_rf | float | latent heat of fusion (J kg$^{-1}$) |\n",
    "| tolerance | float | model tolerance <br>(used to remove low values caused by rounding errors) |\n",
    "| gravity | float | gravity (m s$^{-2}$) |\n",
    "| pressure_std | float | standard pressure (Pa) |\n",
    "| temp_std | float | standard temperature (K) |\n",
    "| R_gas | float | universal gas constant (J mol$^{-1}$ K$^{-1}$) |\n",
    "| molarmass_air | float | molar mass of Earth's air (kg mol$^{-1}$) |\n",
    "\n",
    "(input_debugging_options)=\n",
    "## Debugging Options\n",
    "| Variable | Format/Options | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| debug_refreeze | [True, False] | Used for separate debugging of the heat conduction refreezing scheme |\n",
    "| debug_mb | [True, False] | Used for separate debugging of the mass balance calculations |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(run_calibration_fa_overview_target)=\n",
    "# run_calibration_frontalablation.py\n",
    "This script will perform all pre-processing and calibration required to calibrate the frontal ablation parameterization for marine-terminating glaciers. If successful, the script will run without errors, generate numerous diagnostic plots, and most importantly, produce a .csv file with the calibration outputs.\n",
    "\n",
    "## Script Structure\n",
    "The frontal ablation calibration is a hard-coded script that requires several steps. \n",
    "\n",
    "First, you need to change the region within the run_calibration_frontalablation.py script. \n",
    "\n",
    "Then merge the frontal ablation data together into a single file by setting <em>option_merge_data=True</em>. The hard-coded portion of this option is located in the if statement, so you need to go to where the if statement begins and specify the three filenames that you want to merge together. Additionally, modify the datasets to ensure the data is labeled the same for all three datasets, thereby enabling the merging of the datasets. The output is a merged .csv file that has all the data standardized. This can be considered a pre-processing step.\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_data = True)\n",
    "```\n",
    "Next, calibrate the frontal ablation parameter for each marine-terminating glacier by setting <em>option_ind_calving_k=True</em>. The hard-coded portion of this option is also lcoated in the if statement, so you need to go to where the if statement begins. Here, specify the merged calving filepath and filename as well as the geodetic mass balance dataset. The geodetic mass balance dataset is used to ensure that the frontal ablation estimates do not produce unrealistic climatic mass balance estimates. In the event that they do, a correction is performed to limit the frontal ablation based on a lower bound for the climatic mass balance based on regional mass balance data. This exports a .csv file for each region that includes the calibrated model parameters as well as numerous other columns to be able to compare the observed and modeled frontal ablation as well as the climatic mass balance.\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_ind_calving_k = True)\n",
    "```\n",
    "Then merge all the frontal ablation parameters, which are currently in multiple regional files, into a single file by setting <em>option_merge_calving_k=True</em>.\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_merge_calving_k = True)\n",
    "```\n",
    "Lastly, update the climatic-basal mass balance data by removing the frontal ablation from the total mass change by setting <em>option_update_mb_data=True</em>. This is an important step since the geodetic mass balance data do not account for the mass loss below sea level; however, some of the observed mass change is due to frontal ablation that is above the water level, which is accounted for by this script. This script will export a new \"corrected\" .csv file to replace the previous mass balance .csv file.\n",
    "```\n",
    "python run_calibration_frontalablation.py   (set option_update_mb_data = True)\n",
    "```\n",
    "```{warning}\n",
    "As mentioned, the run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. Additionally, there is specific information within the if statements, which is provided right below the if statements.\n",
    "```\n",
    "```{note}\n",
    "As we continue developing PyGEM, we plan to make this process automated as well and move the pre-processing to a separate script.\n",
    "```\n",
    "\n",
    "## Special Considerations\n",
    "Circularity issues exist in calibrating the frontal ablation parameter as the mass balance model parameters are required to estimate the ice thickness, but the frontal ablation will affect the mass balance estimates and thus the mass balance model parameters. We suggest taking an iterative approach: calibrate the mass balance model parameters, calibrate the frontal ablation parameter, update the glacier-wide climatic mass balance, and recalibrate the mass balance model parameters.\n",
    "\n",
    "Currently only one iteration has been used, but this could be investigated further in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(run_calibration_target)=\n",
    "# run_calibration.py\n",
    "This script will calibrate the mass balance model parameters (degree-day factor of snow, precipitation factor, and temperature bias). If successful, the script will run without errors and the following will be generated:\n",
    "* ../Output/calibration/\\[glacno\\]-modelprms_dict.pkl\n",
    "\n",
    "This is a .pkl file that contains the calibration data. If the file already exists, the calibrated model option will be added to the existing .pkl file.\n",
    "\n",
    "```{note}\n",
    "Use the -debug=1 option in the command line to see the stages of the calibration options.\n",
    "```\n",
    "\n",
    "## Script Structure\n",
    "While most users may just want to run the model, those interested in developing new calibration schemes should be aware of the general structure of the script.  Broadly speaking, the script follows:\n",
    "* Load glaciers\n",
    "* Load reference climate data\n",
    "* Load glacier data (area, etc.)\n",
    "* Load mass balance data\n",
    "* Calibrate the model parameters\n",
    "  - \"Modular\" calibration options are included as an if/elif/else statement.\n",
    "* Export model parameters\n",
    "\n",
    "## View Output\n",
    "The .pkl file stores a dictionary and each calibration option is a key to the dictionary. The model parameters are also stored in a dictionary (i.e., a dictionary within a dictionary) with each model parameter being a key to the dictionary that provides access to a list of values for that specific model parameter. The following shows an example of how to print a list of the precipitation factors ($k_{p}$) for the calibration option specified in the input file:\n",
    "\n",
    "```\n",
    "with open(modelprms_fullfn, 'rb') as f:\n",
    "    modelprms_dict = pickle.load(f)\n",
    "print(modelprms_dict[pygem_prms.option_calibration][‘kp’])\n",
    "```\n",
    "\n",
    "## Special Considerations\n",
    "Typically, the glacier area is assumed to be constant (<em>option_dynamics=None</em>), i.e., the glacier geometry is not updated, to reduce computational expense.\n",
    "\n",
    "Current calibration options rely solely on glacier-wide geodetic mass balance estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(run_calibration_icethickness_overview_target)=\n",
    "# run_calibration_icethickness.py\n",
    "This script will calibrate the ice viscosity (\"Glen A\") model parameter such that the modeled ice volume roughly matches the ice volume estimates from [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3) for each RGI region.\n",
    "\n",
    "If successful, the script will run without error and output the following:\n",
    "* ../Output/calibration/‘glena_region.csv’ \n",
    "\n",
    "## Script Structure\n",
    "The ice thickness calibration is currently hard-coded for the user to specify the regions, and the initial, upper and lower bounds for the Glen's A multiplier, which is the parameter to be calibrated.\n",
    "\n",
    "Broadly speaking, the script follows:\n",
    "* Load glaciers\n",
    "* Select subset of glaciers to reduce computational expense\n",
    "* Load climate data\n",
    "* Run mass balance and invert for initial ice thickness\n",
    "* Use minimization to find agreement between our modeled and [Farinotti et al. (2019)](https://www.nature.com/articles/s41561-019-0300-3) modeled ice thickness estimates for each RGI region\n",
    "* Export the calibrated parameters.\n",
    "\n",
    "## Special Considerations\n",
    "* This code is currently not set up to run automatically as it has the regions hard-coded within the script. The reason for this hard-coding is to be able to run the script, while other scripts are running too (e.g., calibration). This should be changed in the future to facilitate automation though.\n",
    "* In  pygem_input.py, you need to set option_dynamics=‘OGGM’. Otherwise, you’ll get an assertion error telling you to do so, since you won’t be able to record the output otherwise.\n",
    "* While the code runs at the RGI Order 1 region scale, it will only calibrate for the glaciers that have calibration data and run successfully.\n",
    "* pygem_input.py has a parameter ‘icethickness_cal_frac_byarea’ that is used to set the fraction of glaciers by area to include in this calibration. The default is 0.9 (i.e., the largest 90% of glaciers by area). This is to reduce computational expense, since the smallest 10% of glaciers by area contribute very little to the regional volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(run_simulation_target)=\n",
    "# run_simulation.py\n",
    "This script will run the glacier evolution model for the reference climate data or for future climate scenarios. If successful, the script will run without errors and generate one or more netcdf files. The user has the option to export essential statistics (e.g., area, mass, runoff, mass balance components)and/or binned data (e.g., ice thickness, area, mass, mass balance). The output general output will be:\n",
    "* ../Output/simulations/\\[gcm_name\\]/\\[scenario\\]/stats/\\[glac_no\\]...-all.nc\n",
    "\n",
    "When running the script, the GCM and scenario need to be passed via the command line as follows:\n",
    "```\n",
    "python run_simulation.py -gcm_name=[insert_gcm_name] -scenario=[insert_scenario]\n",
    "```\n",
    "\n",
    "## Script Structure\n",
    "While most users may just want to run the model, those interested in developing new calibration schemes should be aware of the general structure of the script.  Broadly speaking, the script follows:\n",
    "* Load glaciers\n",
    "* Load climate data\n",
    "* Bias correct the climate data\n",
    "* Load glacier data (area, etc.)\n",
    "* Load model parameters\n",
    "* Estimate ice thickness\n",
    "* Run simulation\n",
    "* Export model results\n",
    "\n",
    "## View Output\n",
    "Various netcdf files may be generated. To view the results, we recommend using xarray as follows:\n",
    "\n",
    "```\n",
    "ds = xr.open_dataset(filename)\n",
    "print(ds)\n",
    "```\n",
    "\n",
    "## Special Considerations\n",
    "There currently exist a series of try/except statements to ensure model runs are successful. The most common causes of failure are (i) advancing glacier exceeds the \"borders\" defined in OGGM's pre-processing and (ii) numerical instabilities within OGGM's dynamical model. The latter is more common for tidewater glaciers. If you want to avoid these issues, we suggest removing the try/except statements.\n",
    "\n",
    "```{warning}\n",
    "<em>sim_iters</em> in the <em>pygem_input.py</em> specifies the number of iterations. If using MCMC as the calibration option, this becomes important. If you set <em>sim_iters=1</em>, the simulation will run using the median value of each model parameter. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQs\n",
    "### Why does my simulation from run_simulation.py script run smoothly without any error, but the only output is an error folder with a failed information .txt file?\n",
    "The run_simulation.py script uses try/except statements to support large-scale applications, i.e., if a simulation for a single glacier fails (e.g., because it grows beyond the maximum size), we don’t want this error to stop all of the simulations.  Hence, this error is caught in the try/except statement and the except statement generates a failed .txt file to let the individual know that the simulation did not run.\n",
    "\n",
    "Troubleshooting this failure needs to be improved now that there are many new users who will likely cause this to fail more frequently.  At present, the best workaround is to replace the try/except statement.  Specifically, there will be a commented line named “for batman in [0]:”, which I suggest you uncomment, and comment out the try statement above.  You then need to go to towards the end of the statement and uncomment “print(‘\\nADD BACK IN EXCEPTION\\n\\n’)” and comment out the except statement that is about 8 lines of code.  When you run the simulation now, you should get whatever runtime error was causing the failure to begin with.\n",
    "\n",
    "In the future, we will seek to catch these errors and put them in the text file to make debugging easier.\n",
    "\n",
    "\n",
    "### Why is the mass balance that I calculate from the calibration not the same as the simulation?\n",
    "There are three potential causes for this, which are all dependent on the calibration options:\n",
    "1. The calibration is performed assuming the glacier area is constant. This is primarily to save computational time, but also enables the calibration to not be linked to a specific glacier dynamics option. Tests were performed in Fall 2020 that showed the impacts of this over the calibration period (2000-2019) was fairly minor. If you run the model with a dynamical option, then you will get a different mass balance.\n",
    "2. Did you use the emulator? The emulator is a statistical representation of the mass balance. Tests were performed in Fall 2020 that showed the emulator performed quite well (typically within 0.01 - 0.02 mwea of the observed mass balance), which was considered acceptable given the uncertainty associated with the geodetic mass balance data. Hence, the mass balance you get from the emulator will be slightly different than one that you get from running a simulation.\n",
    "3. Did you use the MCMC option?  The MCMC calibration is performed using a certain number of steps.  The simulations are performed for a subset of model parameter combinations from those steps; hence, they will differ.\n",
    "\n",
    "\n",
    "### How can I export a different variable (e.g., binned glacier runoff)?\n",
    "There are two primary steps: (1) calculate the new variable you want to export, and (2) add the variable to the proper dataset.  We recommend the following for this example:\n",
    "\n",
    "Calculate the binned glacier runoff.  You'll see in the massbalance.py script that it automatically adds the glac_bin_melt, glac_bin_refreeze, and bin_prec.  You'll need to create a new variable for glac_bin_runoff.\n",
    "Add the binned glacier runoff to be exported.  For this you need to add the glac_bin_runoff to the create_xrdataset_binned_stats() function in the run_simulation.py script.  This will add the glacier runoff as a binned result to the binned netcdf file that is exported.\n",
    "\n",
    "\n",
    "### Why am I getting a 'has_internet'=False error?\n",
    "Part of the beauty of our use of OGGM is access to the OGGM Shop. When we initialize our glacier directories in PyGEM, we are downloading them from OGGM shop.  OGGM has a cfg.PARAMS['has_internet'] variable that must be set to True in order to download; otherwise, it will throw this error.  If you skipped over running OGGM's test when you downloaded OGGM, you may not have downloaded the sample datasets that OGGM requires to run tests and it'll likely throw an error.  To correct this error, you have two options: (1) set <em>has_internet=True</em> in pygem_input.py or (2) manually modify your code to set <em>cfg.PARAMS['has_internet']=True</em> likely somewhere in your oggm_compat.py file, which will be located somewhere in your conda environment if you used pip install.\n",
    "\n",
    "\n",
    "### The error message and line of code appears to be associated with code from OGGM. How do I troubleshoot OGGM's code from within PyGEM?\n",
    "While we're doing everything we can to minimize these issues, and OGGM developers are excellent at supporting this as well, from time to time errors may come up based on OGGM. This often occurs during changes between versions as it's challenging to document every tiny change. Nonetheless, here's a guide for troubleshooting your errors to at least identify the problem. We'll use a recent example where for some reason with the new update, we couldn't get tidewater glaciers to invert for ice thickness. Here's what we did to solve the issue:\n",
    "* Identify the source code associated with the error.\n",
    "  - In our case, we couldn't get the inversion to work, so we knew it was associated with OGGM's core/inversion.py. If you're having trouble with this step, try copying a function from the error message and finding where that function exists in OGGM's source code on github.\n",
    "* Find where OGGM’s code is installed in your environment on your local computer.\n",
    "  - A good way to do this is to go to your directory and find where \"inversion.py\" exists. Then open this file and show the enclosing directory. Note that this can be a bit of a pain, but once you know where your conda environments are stored it makes it a lot easier. This is essentially where the packages are stored on your computer. Cool!\n",
    "* Find where the error is coming from by putting print statements within the inversion.py script.\n",
    "  - This is very basic troubleshooting. There are likely faster ways of doing so, but I prefer to dive into the code. In our case, the model_flowlines wasn’t being generated, so I started going through the find_inversion_calving_from_any_mb fxn. This identified that it was not even getting pass the first if statement, which is a clever thing that OGGM does - OGGM has built-in \"off-ramps\" within their functions such that if the input structure isn’t ideal (in this case if it’s not a tidewater glacier or if you don’t set cfg.PARAMS[‘use_kcalving_for_inversion’]=True, then it returns out of the function without an error.\n",
    "* Lastly, come up with a solution!\n",
    "  - This is where our help breaks down a bit as you'll need to figure out what the fix is for your situation. However, if you're able to get to this point, stay at it! If you are trying hard and can't figure out what's going on (perhaps you've tried for a couple hours and are now getting super frustrated - it happens), this is where using the \"support\" Channel on OGGM's Slack is a great option. In your message, make sure to include all the details above. If it's something with PyGEM, then the PyGEM folks on OGGM's Slack will do our best to help. If it's something with OGGM, then you'll find plenty of support as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do list:\n",
    "* Add automatic function/class list!\n",
    "* Convert .pkl calibration files to .json\n",
    "* Add simple model script for processing output\n",
    "* Add simple model script for analyzing output with various options\n",
    "* Add sample data for tidewater glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
