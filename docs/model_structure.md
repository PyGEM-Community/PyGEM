(model_structure_and_workflow_target)=
# Model Structure and Workflow
The model is written in Python. The model is currently available as two repositories on github:

1. **PyGEM** ([https://github.com/drounce/PyGEM](https://github.com/drounce/PyGEM)) contains the main model code.  This repository can be installed in your environment with PyPI ([https://pypi.org/project/pygem/](https://pypi.org/project/pygem/)) using "pip install pygem".

2. **PyGEM-scripts** ([https://github.com/drounce/PyGEM-scripts](https://github.com/drounce/PyGEM-scripts)) contains general scripts used to run the model (e.g., run_calibration.py, run_simulation.py) as well as the post-processing, analysis scripts (e.g., analyze_simulations.py). To use these files and run the model one must clone or fork the github repository onto your local machine.

All input parameters are specified in the pygem_input.py file, which needs to be adjusted according to the specific datasets and model options of each user. The input file is [well documented](pygem_input_overview_target) and [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ) are produced to support trial runs. See the [Install_PyGEM](install_pygem_target) section for more details on installing the model.

## Spatial and Temporal Resolution
PyGEM models each glacier independently using a monthly timestep and elevation bins. We plan to add options to include daily timesteps in the near future and plan to develop new calibration options that can leverage regional datasets as well.

(directory_structure_target)=
## Directory structure
Currently, the model does not have a “required” set of directories. For simplicity with github, we highly recommend keeping the forked version of the code in its own directory. Furthermore, since many of the datasets that will be used for regional and global model runs are of considerable size, we encourage users to develop their own organized file structure. The code has been developed to automatically set up all file paths using relative paths from the PyGEM-Scripts directory, which is where the code is run from the command line. The easiest way to run PyGEM will be to use the same directory structure as the developers (see [sample files](https://drive.google.com/drive/folders/13kiU00Zz2swN5OzwXiWIQTj_JLEHnDgZ)):

* [climate_data](climate_data_target)
  - This directory contains the reference and future climate data
* [debris_data](input_debris_data_target) (optional)
  - This directory contains data concerning the debris thickness and sub-debris melt enhancement factors. 
* [DEMs](input_mb_data_target)
  - This directory contains the geodetic mass balance data derived from DEM differencing that is used for calibration.
* [IceThickness_Farinotti](input_thickness_data_target) (optional)
  - This directory includes the consensus ice thickness estimates (Farinotti et al. 2019). The directory is optional unless you want to match the consensus ice thickness estimates.
* [oggm_gdirs](input_glacier_data_target)
  - This directory contains the glacier directories downloaded from OGGM. This directory will be automatically generated by the pre-processing steps from OGGM.
* Output
  - This directory contains all model output
* PyGEM (optional)
  - This directory contains all model functions and is used when in development mode if pygem is not installed in the conda environment.
* [PyGEM-scripts](scripts_overview_target)
  - This directory contains scripts to run the model and process output
* [RGI](input_glacier_inventory_target)
  - This directory contains the RGI glacier information
* [WGMS](input_mb_data_target) (optional)
  - This directory contains the WGMS mass balance data for validation. The directory is optional in case you prefer to validate your model with different data.
  
```{warning}
If you use a different file structure and do not update the file paths in the **pygem_input.py**, you will get an error and PyGEM will not run!
```

(model_workflow_target)=
## Model Workflow
The model code itself is heavily commented with the hope that the code is easy to follow and develop further. After [installing PyGEM](install_pygem_target), downloading the required [input files](model_inputs_target), and setting up the [directory structure](directory_structure_target) (or modifying the **pygem_input.py** with your preferred directory structure) you are ready to run the code! Generally speaking, the workflow includes:
* [Pre-process data](preprocessing_target) <em>(optional if including more data)</em>
* [Set up input file](input_workflow_target)
* [Calibrate frontal ablation parameter](workflow_cal_frontalablation_target) <em>(optional for marine-terimating glaciers)</em>
* [Calibrate mass balance parameters](workflow_cal_prms_target)
* [Calibrate ice viscosity parameter](workflow_cal_glena_target)
* [Run model simulation](workflow_sim_target)
* [Post-process output](workflow_post_target)
* [Analyze output](workflow_analyze_target)


(preprocessing_target)=
### Pre-processing 
We rely heavily on [OGGM's pre-processing modules](https://docs.oggm.org/en/stable/shop.html), which are state-of-the-art. For most people, these glacier directories will be sufficient to get started. However, there are times when we work with different datasets and need to do our own pre-processing. For example, the following script corrects the geodetic mass balance from [Hugonnet et al. (2021)](https://www.nature.com/articles/s41586-021-03436-z) to account for the mass lost below the water level due to frontal ablation from [Kochtitzky et al. (2022)](https://www.nature.com/articles/s41467-022-33231-x).
```
python run_preprocessing_wgms_mbdata.py -mb_data_removeFA=1
```


(input_workflow_target)=
### Set up input file
**pygem_input.py** is the input file where the user can specify the glaciers/regions to model; model physics, calibration, and simulation options; relative filepaths for relevant datasets; etc. 

For more details, see the [pygem_input.py Script Overview](pygem_input_overview_target).

```{note}
The first time you process glacier directories (e.g., happens automatically with the run_calibration.py), you want to set <em>overwrite_gdirs=True</em> in pygem_input.py. This will add the mass balance and consensus ice thickness data to the glacier directories.  To avoid redownloading/reprocessing the glacier directories every time, after performed once set <em>overwrite_gdirs=False</em>.
```

(workflow_cal_prms_target)=
### Calibrate mass balance model parameters
The model parameters (degree-day factor of snow, precipitation factor, and temperature bias) must be calibrated for model results to be meaningful. This is done using **run_calibration.py**. Several options exist (see [Model Calibration](calibration_target) for specific details), but generally speaking the <em>option_calibration</em> will be specified in **pygem_input.py** and then the following is run:
```
python run_calibration.py
```
```{note}
The Markov Chain Monte Carlo (MCMC) methods require several steps and additional python packages (i.e., PyMC2 and its dependencies. See [MCMC methods](MCMC_target) or [Test MCMC methods](test_advanced_target) for the specific workflow.
```
If successful, the script will run without error and output the following:
* ../Output/calibration/\[RGI Order 1 region\]/\[glac_no\]-model_prms.pkl 
* additional files will be generated if using the emulator

For more details, see the [run_calibration.py Script Overview](run_calibration_target).


(workflow_cal_frontalablation_target)=
### Calibrate frontal ablation parameter
**(Optional)** If you want to account for frontal ablation associated with marine-terminating glaciers, then the frontal ablation parameter needs to be calibrated. This is done using **run_calibration_frontalablation.py** with the following steps:

First, merge the frontal ablation data together into a single directory:
```
python run_calibration_frontalablation.py   (set option_merge_data = True)
```
Calibrate the frontal ablation parameter for each marine-terminating glacier:
```
python run_calibration_frontalablation.py   (set option_ind_calving_k = True)
```
Merge all the frontal ablation parameters into a single file:
```
python run_calibration_frontalablation.py   (set option_merge_calving_k = True)
```
Update the climatic-basal mass balance data by removing the frontal ablation from the total mass change:
```
python run_calibration_frontalablation.py   (set option_update_mb_data = True)
```
```{note}
The run_calibration_frontalablation.py script is hard-coded with True/False options so one must manually go into the script and adjust the options. 
```
If successful, the script will run without error and output the following:
* ../calving_data/analysis/all-calving_cal_ind.csv
* ../DEMs/Hugonnet2020/df_pergla_20yr-filled-FAcorrected.csv

For more details, see the [run_calibration_frontalablation.py Script Overview](run_calibration_fa_overview_target).

```{warning}
Circularity issues exist in calibrating the frontal ablation parameter as the mass balance model parameters are required to estimate the ice thickness, but the frontal ablation will affect the mass balance estimates and thus the mass balance model parameters. We suggest taking an iterative approach: calibrate the mass balance model parameters, calibrate the frontal ablation parameter, update the glacier-wide climatic mass balance, and recalibrate the mass balance model parameters.
```


(workflow_cal_glena_target)=
### Calibrate ice viscosity model parameter
The ice viscosity ("Glen A") model parameter is calibrated such that the ice volume estimated using the calibrated mass balance gradients are consistent with the consensus ice volume estimates ([Farinotti et al. 2019]((https://www.nature.com/articles/s41561-019-0300-3))) for each RGI region. This is done by running the following:
```
python run_calibration_icethickness_consensus.py
```
```{note}
This code is hard-coded and thus the user will have to go in and change regions.
```
If successful, the script will run without error and output the following:
* ../Output/calibration/‘glena_region.csv’ 

For more details, see the [run_calibration_icethickness.py Script Overview](run_calibration_icethickness_overview_target).


(workflow_sim_target)=
### Run model simulation
Model simulations are performed using run_simulation.py. If no GCMs are specified in the command line, the default will be to run a model simulation with the reference data (e.g., ERA5). We currently recommend that <br><em>**historical simulations**</em> be performed without evolving the glacier geometry; thus, <em>option_dynamics = None</em> in **pygem_input.py** and the <em>ref_startyear</em> and <em>ref_endyear</em> are used to set the length of the simulation. The simulation can then be run using the following:
```
python run_simulation.py
```
<em>**Future simulations**</em> require specifying a GCM and scenario, which is passed to the script through the argument parser. For example, the following will run a simulation for CESM2 SSP2-4.5:
```
python run_simulation.py -gcm_name='CESM2' -scenario='ssp245'
```
```{note}
For future simulations, at a minimum the user should specify the dynamical option (<em>option_dynamics</em>), start year (<em>gcm_startyear</em>), end year (<em>gcm_endyear</em>), bias correction option (<em>option_bias_adjustment</em>).
```
If successful, the script will run without error and output the following:
* ../Output/simulation/\[RGI Order 1 region\]/\[GCM name\]/\[Scenario\]/stats/\[glac_no\]_\[GCM name\]_\[Scenario\]_\[Calibration Option\]_ba\[bias adjustment option\]_\[number of simulations\]_\[start year\]_\[end year\]_all.nc
* additional netcdf files may be output based on the user specifications in pygem_input.py

For more details, see the [run_simulation.py Script Overview](run_simulation_target).


(workflow_post_target)=
### Post-process output
There are currently several scripts available to process the datasets (e.g., merge them into regional files, create multi-GCM means and standard deviations for each SSP). While these scripts are well documented in line, they still need to be cleaned up for more widespread use.  An example:
```
python process_simulation.py
```


(workflow_analyze_target)=
### Analyze output
All users will analyze PyGEM output in different ways. The following is thus not meant to be an exhaustive list of analyses, but rather to provide some general scripts to produce diagnostic figures of mass, area, runoff, and ice thickness change. These scripts will also help you get familiar with working with the model and post-processed outputs. We are currently provide these scripts as Jupyter Notebooks, so you can visualize the expected output and use this to guide your efforts. These will be listed in <em>PyGEM-scripts</em> beginning with "analyze_". For example:
* **analyze_glacier_change_byRGIRegion.ipynb**
  - This notebook shows mass, area, and runoff changes with model output aggregated to RGI regions. Note that this notebook relies on [post-processed output](workflow_post_target).
* **analyze_glacier_change_byWatershed.ipynb**
  - This notebook shows mass, area, and runoff changes with model output aggregated to user-specified groups (watersheds are used in this example). Note that this notebook relies on [post-processed output](workflow_post_target). 
<br>For individual glacier changes, we recommend:
* **analyze_glacier_change_CrossSection.ipynb**
  - This notebook shows a cross section of ice thickness change and normalized mass change for a single glacier.

At present, publication-quality figures of mass, area, and runoff change are also provided in case you want to investigate more complex figures. Figure options and pathways are hard-coded within these scripts. An example:
```
python analysis_Science_figs.py
```

For more detail, see [Model Output Section](model_output_overview_target).